{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# CIFAR-10 데이터셋 로드 및 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 임의로 데이터를 오염시키는 함수 (여기서는 이미지를 흰색으로 바꾸는 방식)\n",
    "def add_noise(x, noise_factor=0.5):\n",
    "    noise = torch.randn_like(x) * noise_factor\n",
    "    x_noisy = x + noise\n",
    "    return torch.clamp(x_noisy, 0., 1.)\n",
    "\n",
    "# Non-Local Means 필터\n",
    "def non_local_means(img, patch_size=5, search_window_size=21, h=1.0):\n",
    "    \"\"\"\n",
    "    Non-Local Means Denoising\n",
    "    :param img: 노이즈가 포함된 이미지 (Tensor, 크기: [C, H, W])\n",
    "    :param patch_size: 각 패치의 크기 (정수)\n",
    "    :param search_window_size: 검색 창의 크기 (정수)\n",
    "    :param h: 필터의 강도 (작을수록 더 강한 필터링)\n",
    "    :return: denoised image\n",
    "    \"\"\"\n",
    "    C, H, W = img.shape\n",
    "    half_patch_size = patch_size // 2\n",
    "    half_search_window = search_window_size // 2\n",
    "    \n",
    "    # 결과 이미지 초기화\n",
    "    denoised_img = torch.zeros_like(img)\n",
    "\n",
    "    # 패치와 검색창의 모든 좌표에 대해 반복\n",
    "    for c in range(C):\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                patch = img[c, max(i-half_patch_size, 0):min(i+half_patch_size+1, H), max(j-half_patch_size, 0):min(j+half_patch_size+1, W)]\n",
    "                patch_flat = patch.view(-1)\n",
    "                \n",
    "                weights = []\n",
    "                for di in range(max(i-half_search_window, 0), min(i+half_search_window+1, H)):\n",
    "                    for dj in range(max(j-half_search_window, 0), min(j+half_search_window+1, W)):\n",
    "                        neighbor_patch = img[c, max(di-half_patch_size, 0):min(di+half_patch_size+1, H), max(dj-half_patch_size, 0):min(dj+half_patch_size+1, W)]\n",
    "                        neighbor_patch_flat = neighbor_patch.view(-1)\n",
    "                        \n",
    "                        # 유클리드 거리 계산\n",
    "                        dist = torch.norm(patch_flat - neighbor_patch_flat)\n",
    "                        weight = torch.exp(-dist**2 / (h**2))\n",
    "                        weights.append((weight, (di, dj)))\n",
    "                \n",
    "                # 가중치 기반으로 값 계산\n",
    "                norm_weights = sum([w[0] for w in weights])\n",
    "                weighted_sum = sum([img[c, w[1][0], w[1][1]] * w[0] for w in weights])\n",
    "                denoised_img[c, i, j] = weighted_sum / norm_weights if norm_weights != 0 else img[c, i, j]\n",
    "                \n",
    "    return denoised_img\n",
    "\n",
    "# NLM을 적용하여 이미지 복원\n",
    "def denoise_image(image, patch_size=5, search_window_size=21, h=1.0):\n",
    "    return non_local_means(image, patch_size, search_window_size, h)\n",
    "\n",
    "# CIFAR-10 이미지에 대해 NLM을 적용하여 복원\n",
    "def apply_nlm_on_batch(batch, patch_size=5, search_window_size=21, h=1.0):\n",
    "    batch_denoised = []\n",
    "    for img in batch:\n",
    "        denoised_img = denoise_image(img)\n",
    "        batch_denoised.append(denoised_img)\n",
    "    \n",
    "    return torch.stack(batch_denoised)\n",
    "\n",
    "# 모델 훈련 (NLM은 비지도 학습이므로 훈련이 필요하지 않음)\n",
    "# 테스트 데이터셋에 대한 복원\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_data = next(iter(testloader))\n",
    "    test_inputs, test_labels = test_data\n",
    "    noisy_test_inputs = add_noise(test_inputs)\n",
    "\n",
    "    # NLM을 사용하여 복원된 이미지 얻기\n",
    "    restored_images = apply_nlm_on_batch(noisy_test_inputs)\n",
    "\n",
    "# 복원된 이미지와 원본 이미지 비교\n",
    "n = 10  # 이미지 갯수\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # 원본\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(test_inputs[i].permute(1, 2, 0) / 2 + 0.5)\n",
    "    plt.title(\"Original\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # 복원된 이미지\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(restored_images[i].permute(1, 2, 0) / 2 + 0.5)\n",
    "    plt.title(\"Restored by NLM\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TSNE 모델 클래스 정의\n",
    "class TSNE_Model(torch.nn.Module):\n",
    "    def __init__(self, n_components=2, perplexity=30.0, n_iter=1000):\n",
    "        super(TSNE_Model, self).__init__()\n",
    "        self.n_components = n_components\n",
    "        self.perplexity = perplexity\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X: (N, D) tensor, where N is the number of data points and D is the dimension of each data point\n",
    "        \"\"\"\n",
    "        X = X.detach().cpu().numpy()  # PyTorch tensor -> NumPy array\n",
    "        tsne = TSNE(n_components=self.n_components, perplexity=self.perplexity, n_iter=self.n_iter)\n",
    "        tsne_results = tsne.fit_transform(X)\n",
    "        return torch.tensor(tsne_results, dtype=torch.float32).to(X.device)\n",
    "\n",
    "# 학습 함수\n",
    "def train_model(model, trainloader, device='cuda', epochs=10, Data_Reset=False, net_reset=False, \n",
    "                folder_path='./', net_name=\"default_net.pt\", log_save=True, log_name=\"default_log.npy\"):\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        print(\"디렉토리 없음\")\n",
    "        if not net_reset and not Data_Reset:\n",
    "            return\n",
    "        os.mkdir(folder_path)\n",
    "        print(\"디렉토리를 만들었습니다:\", folder_path)\n",
    "    \n",
    "    os.chdir(folder_path)\n",
    "\n",
    "    if not os.path.exists(net_name) and not net_reset:\n",
    "        print(\"학습데이터 없음\")\n",
    "        os.chdir(\"../\")\n",
    "        return\n",
    "\n",
    "    # DataLoader에서 데이터 항목 개수 확인\n",
    "    for batch in trainloader:\n",
    "        num_items = len(batch)  # 배치에서 항목 개수 확인\n",
    "        print(\"데이터 항목 수:\", num_items)\n",
    "        break\n",
    "\n",
    "    # 모델 초기화 또는 데이터 초기화가 필요한 경우\n",
    "    if net_reset or Data_Reset or (not os.path.exists(net_name)):\n",
    "        model.train()\n",
    "        loss_list = []\n",
    "\n",
    "        criterion = nn.MSELoss()  # 손실 함수\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for data in trainloader:\n",
    "                if num_items == 2:\n",
    "                    inputs, _ = data\n",
    "                elif num_items == 4:\n",
    "                    _, _, inputs, _ = data\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                # TSNE 모델에 데이터를 전달하여 차원 축소\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # 손실 계산 (이 경우엔 차원 축소된 결과와 원본 데이터를 비교하지 않음)\n",
    "                # 차원 축소 모델이므로 손실 계산은 생략할 수 있음\n",
    "                # loss = criterion(outputs, inputs)  # 차원 축소는 손실을 계산하지 않음\n",
    "\n",
    "                # 손실 없이 그냥 출력값만 업데이트 (TSNE는 지도 학습이 아닌 차원 축소 모델이므로)\n",
    "                # running_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{epochs}]')\n",
    "\n",
    "        # 모델 저장\n",
    "        torch.save(model.state_dict(), net_name)\n",
    "        print(f\"모델을 저장하였습니다: {net_name}\")\n",
    "        \n",
    "        if log_save:\n",
    "            np.save(log_name, np.array(loss_list))\n",
    "            print(f\"로그를 저장하였습니다: {log_name}.npy\")\n",
    "        \n",
    "        os.chdir(\"../\")\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        if not os.path.exists(log_name + \".npy\"):\n",
    "            print(\"학습 로그 없음\")\n",
    "        else:\n",
    "            loss_list = np.load(log_name + \".npy\")\n",
    "            print(\"로그 로드됨\")\n",
    "\n",
    "        os.chdir(\"../\")\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

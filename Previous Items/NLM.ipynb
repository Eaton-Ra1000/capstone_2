{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchvision import transforms\n",
    "\n",
    "# CIFAR-10 데이터셋 로드 및 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 임의로 데이터를 오염시키는 함수 (여기서는 이미지를 흰색으로 바꾸는 방식)\n",
    "def add_noise(x, noise_factor=0.5):\n",
    "    noise = torch.randn_like(x) * noise_factor\n",
    "    x_noisy = x + noise\n",
    "    return torch.clamp(x_noisy, 0., 1.)\n",
    "\n",
    "# t-SNE 시각화를 위한 데이터 전처리 (flatten과 표준화)\n",
    "def prepare_for_tsne(data):\n",
    "    data_flat = data.view(data.size(0), -1)  # 이미지 데이터를 1D 벡터로 변환\n",
    "    return data_flat\n",
    "\n",
    "# Denoising Autoencoder 정의\n",
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        # 인코더\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        # 디코더\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256 * 4 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64 * 8 * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (64, 8, 8)),\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "model = DenoisingAutoencoder().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 훈련\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:\n",
    "        inputs, _ = data\n",
    "        noisy_inputs = add_noise(inputs).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(noisy_inputs)\n",
    "        loss = criterion(outputs, inputs.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
    "\n",
    "# 테스트 데이터셋에 대한 복원\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_data = next(iter(testloader))\n",
    "    test_inputs, test_labels = test_data\n",
    "    noisy_test_inputs = add_noise(test_inputs).cuda()\n",
    "\n",
    "    restored_images = model(noisy_test_inputs.cuda())\n",
    "\n",
    "# 복원된 이미지와 원본 이미지 비교\n",
    "n = 10  # 이미지 갯수\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # 원본\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(test_inputs[i].permute(1, 2, 0) / 2 + 0.5)\n",
    "    plt.title(\"Original\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # 복원된 이미지\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(restored_images[i].cpu().permute(1, 2, 0) / 2 + 0.5)\n",
    "    plt.title(\"Restored\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# t-SNE 시각화\n",
    "def plot_tsne(original_data, noisy_data, labels):\n",
    "    original_data_flat = prepare_for_tsne(original_data)\n",
    "    noisy_data_flat = prepare_for_tsne(noisy_data)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    original_data_flat = scaler.fit_transform(original_data_flat.cpu().numpy())\n",
    "    noisy_data_flat = scaler.transform(noisy_data_flat.cpu().numpy())\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    original_tsne = tsne.fit_transform(original_data_flat)\n",
    "    noisy_tsne = tsne.fit_transform(noisy_data_flat)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(original_tsne[:, 0], original_tsne[:, 1], c=labels.numpy(), cmap='jet', alpha=0.5, label=\"Original\")\n",
    "    plt.scatter(noisy_tsne[:, 0], noisy_tsne[:, 1], c=labels.numpy(), cmap='jet', marker='x', alpha=0.5, label=\"Noisy\")\n",
    "    plt.title(\"t-SNE visualization of Original vs Noisy CIFAR-10\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# t-SNE 시각화 수행\n",
    "plot_tsne(test_inputs, noisy_test_inputs, test_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

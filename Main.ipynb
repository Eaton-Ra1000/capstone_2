{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgnERK0iT7U_"
   },
   "source": [
    "### 함수 저장소\n",
    "\n",
    "1. 학습 데이터셋 비교 가시화\n",
    "\n",
    "visualize_multiple_dataloaders([test_loader], test_loader, images_per_loader=5)\n",
    "\n",
    "2. 실험 진행용 학습모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSD6sI1ojEfo"
   },
   "source": [
    "### 1. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K0k8rocQiudv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLjVNkuKCpcG",
    "outputId": "5ed1d8c3-224d-47b4-cf51-c229da4eb7b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Master Switch Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Retrain Option\n",
    "#모델 리셋\n",
    "Data_Reset = True\n",
    "#학습된 모델 없등면 자동으로 학습\n",
    "Auto_Init = True\n",
    "defualt_epoch = 2\n",
    "#Model Save Path\n",
    "default_path = \"default_path\"\n",
    "#로그 기록 여부\n",
    "log_save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Automated Git Ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gitignore(directory = default_path, gitignore_path=\".gitignore\"):\n",
    "\n",
    "    # .gitignore 파일이 존재하는지 확인\n",
    "    if not os.path.exists(gitignore_path):\n",
    "        print(f\"{gitignore_path} 파일이 존재하지 않습니다. 새로 생성합니다.\")\n",
    "        with open(gitignore_path, 'w') as f:\n",
    "            f.write(\"\")  # 빈 .gitignore 파일 생성\n",
    "    \n",
    "    # .gitignore 파일을 읽기\n",
    "    with open(gitignore_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # 이미 디렉토리가 .gitignore에 있는지 확인\n",
    "    ignore_line = f\"{directory}/\\n\"\n",
    "    if ignore_line not in lines:\n",
    "        # 디렉토리가 없으면 추가\n",
    "        with open(gitignore_path, 'a') as f:\n",
    "            f.write(ignore_line)\n",
    "        print(f\"{directory} 디렉토리를 .gitignore에 추가했습니다.\")\n",
    "    else:\n",
    "        print(f\"{directory} 디렉토리가 이미 .gitignore에 존재합니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nc6NvqDWjJjl"
   },
   "source": [
    "### 2. 데이터셋 정의 - 비오염"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n93dhuI8kEqb"
   },
   "outputs": [],
   "source": [
    "# Data loading and transformations\n",
    "transform = transforms.Compose([\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.RandomCrop(32, padding=4),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1YfR7U4CCn_",
    "outputId": "b2ca1462-5373-4ef9-ef4c-b8be73959186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Use PyTorch's torchvision.transforms.ToTenesor() to convert the dataset to tensor format\n",
    "train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "add_set = CIFAR100(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Iv1xifZj_B5Q"
   },
   "outputs": [],
   "source": [
    "# Use PyTorch's DataLoader to divide the dataset into mini-batches and load the data\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=False)\n",
    "add_loader = DataLoader(dataset=add_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eYGOwI2lrw3l"
   },
   "outputs": [],
   "source": [
    "def visualize_multiple_dataloaders(dataloaders, trainloader, images_per_loader=5):\n",
    "    num_loaders = len(dataloaders)\n",
    "    classes = trainloader.dataset.classes\n",
    "\n",
    "    # 플롯 크기 설정\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    for batch in train_loader:\n",
    "        num_items = len(batch)  # 배치에서 항목 개수 확인\n",
    "        print(\"Number of Data Type:\", num_items)\n",
    "        break\n",
    "\n",
    "    for i, loader in enumerate(dataloaders):\n",
    "        # 각 DataLoader에서 배치 하나 가져오기\n",
    "        batch = next(iter(loader))\n",
    "        if num_items == 2:\n",
    "            images, labels = batch\n",
    "        if num_items == 4:\\\n",
    "            _ , _, images, labels = batch\n",
    "        images = torch.clamp(images, 0, 1)  # 이미지를 0과 1 사이로 클리핑하여 표시 문제 방지\n",
    "\n",
    "        # 각 DataLoader에서 선택한 이미지 수만큼 시각화\n",
    "        for j in range(images_per_loader):\n",
    "            idx = i * images_per_loader + j\n",
    "            plt.subplot(num_loaders, images_per_loader, idx + 1)\n",
    "            plt.imshow(images[j].permute(1, 2, 0))  # 이미지 차원 변경: (C, H, W) -> (H, W, C)\n",
    "            plt.title(classes[labels[j].item()])\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVF7GSn9jOB5"
   },
   "source": [
    "### 3. 신경망 코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YxUFFR4Akpau"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Autoencoder 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder 부분\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),   # 32x32 -> 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # 16x16 -> 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1), # 8x8 -> 4x4\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128)  # latent space (압축된 표현)\n",
    "        )\n",
    "        \n",
    "        # Decoder 부분\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256 * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (256, 4, 4)),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1), # 4x4 -> 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),   # 8x8 -> 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),     # 16x16 -> 32x32\n",
    "            nn.Tanh()  # 0~1 범위로 출력\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. U-Net 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # 인코더 (Contracting Path)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # 32x32 -> 16x16\n",
    "        )\n",
    "        \n",
    "        self.encoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # 16x16 -> 8x8\n",
    "        )\n",
    "        \n",
    "        self.encoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # 8x8 -> 4x4\n",
    "        )\n",
    "\n",
    "        # 병목층 (Bottleneck)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 디코더 (Expanding Path)\n",
    "        self.decoder_1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')  # 4x4 -> 8x8\n",
    "        )\n",
    "        \n",
    "        self.decoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')  # 8x8 -> 16x16\n",
    "        )\n",
    "        \n",
    "        self.decoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')  # 16x16 -> 32x32\n",
    "        )\n",
    "        \n",
    "        # 최종 출력 레이어\n",
    "        self.final_conv = nn.Conv2d(64, 3, kernel_size=3, padding=1)  # 출력 채널 3 (RGB 이미지)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 인코더\n",
    "        enc1 = self.encoder(x)\n",
    "        enc2 = self.encoder_2(enc1)\n",
    "        enc3 = self.encoder_3(enc2)\n",
    "        \n",
    "        # 병목층\n",
    "        bottleneck = self.bottleneck(enc3)\n",
    "        \n",
    "        # 디코더\n",
    "        dec1 = self.decoder_1(bottleneck)\n",
    "        dec2 = self.decoder_2(dec1)\n",
    "        dec3 = self.decoder_3(dec2)\n",
    "        \n",
    "        # 최종 출력\n",
    "        out = self.final_conv(dec3)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5haTn0vlaFa"
   },
   "source": [
    "### 4. 신경망 학습과 테스트 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic Train and evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yJhbIRtSqUIN"
   },
   "outputs": [],
   "source": [
    "# Train and evaluate function\n",
    "def train_and_evaluate(model, train_loader, test_loader, device = device, epochs=defualt_epoch, \\\n",
    "                       Data_Reset = Data_Reset, net_reset = False, folder_path = default_path, \\\n",
    "                       net_name = \"defual_net.pt\", log_save = log_save, log_name = \"default_log\"):\n",
    "  \n",
    "  if os.path.exists(folder_path)== False:\n",
    "    print(\"디렉토리 없음\")\n",
    "    if net_reset == False and Data_Reset == False and Auto_Init == False:\n",
    "      return\n",
    "  \n",
    "    os.mkdir(folder_path)\n",
    "    print(\"디렉토리를 만들었습니다 : \", folder_path)\n",
    "    gitignore(directory = folder_path)\n",
    "  \n",
    "  os.chdir(folder_path)\n",
    "\n",
    "  if os.path.exists(net_name) == False and Auto_Init == False:\n",
    "      print(\"학습데이터 없음\")\n",
    "      os.chdir(\"../\")\n",
    "      return\n",
    "\n",
    "  if net_reset == True or Data_Reset == True or (os.path.exists(net_name) == False and Auto_Init == True):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # DataLoader에서 데이터 항목 개수 확인\n",
    "    for batch in train_loader:\n",
    "        num_items = len(batch)  # 배치에서 항목 개수 확인\n",
    "        print(\"Number of Data Type:\", num_items)\n",
    "        break\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      running_loss = 0.0\n",
    "\n",
    "      if num_items == 2:\n",
    "        for data in train_loader:\n",
    "            original_images, original_labels = data\n",
    "            original_images, original_labels = original_images.to(device), original_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(original_images)\n",
    "            loss = criterion(outputs, original_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "      \n",
    "      elif num_items == 4:\n",
    "        for data in train_loader:\n",
    "            _, _, poisoned_images, poisoned_labels = data\n",
    "            poisoned_images, poisoned_labels = poisoned_images.to(device), poisoned_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(poisoned_images)\n",
    "\n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, poisoned_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "      elif num_items == 5:\n",
    "        for data in train_loader:\n",
    "            _, _, _, poisoned_labels, restoed_images = data\n",
    "            restored_images, poisoned_labels = restored_images.to(device), poisoned_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(restoed_images)\n",
    "\n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, poisoned_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "      else :\n",
    "          print(\"dataset error\")\n",
    "          return \n",
    "        \n",
    "      print(f'[Epoch {epoch + 1}] loss: {running_loss / len(train_loader):.3f}')\n",
    "\n",
    "      accuracy = evaluate(model, device, test_loader)\n",
    "      accuracies.append(accuracy)\n",
    "      print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    torch.save(model, net_name)\n",
    "    print(\"모델을 저장하였습니다 : \", net_name)\n",
    "    \n",
    "    if log_save == True or Data_Reset == True or (os.path.exists(net_name) == False and Auto_Init == True):\n",
    "      np.save(log_name, accuracies)\n",
    "      print(\"로그를 저장하였습니다 : \", log_name, \".npy\")\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "      \n",
    "  \n",
    "  else:  \n",
    "    if os.path.exists(log_name+\".npy\")== False:\n",
    "      print(\"accuracies 없음 (모델 로드가능)\")\n",
    "      accuracies = []\n",
    "\n",
    "    else:  \n",
    "      accuracies_np = np.load(log_name+\".npy\")\n",
    "      accuracies = accuracies_np.tolist()\n",
    "      print(\"accuracies 로드됨\")\n",
    "  print(os.getcwd())\n",
    "  \n",
    "  os.chdir(\"../\")\n",
    "  return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XJD8q_BHlfkv"
   },
   "outputs": [],
   "source": [
    "# Evaluate function\n",
    "def evaluate(model, device, test_loader, ex_load = False, load_dict = \"./default_net.pt\"):\n",
    "  if ex_load == True :\n",
    "    model = torch.load(load_dict)\n",
    "  model.eval()\n",
    "  total_correct = 0\n",
    "  with torch.no_grad():\n",
    "     for data, target in test_loader:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      output = model(data)\n",
    "      _, preds = torch.max(output, 1)\n",
    "      total_correct += (preds == target).sum().item()\n",
    "\n",
    "  accuracy = 100 * total_correct / len(test_loader.dataset)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Image Restoration Neural Network Train Function\n",
    "##### Autoencoder/ Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def train_model(model, trainloader, device = device,  epochs=defualt_epoch, \\\n",
    "                       Data_Reset = Data_Reset, net_reset = False, folder_path = default_path, \\\n",
    "                       net_name = \"defual_net.pt\", log_save = log_save, log_name = \"default_log\"):\n",
    "    \n",
    "    if os.path.exists(folder_path)== False:\n",
    "        print(\"디렉토리 없음\")\n",
    "        if net_reset == False and Data_Reset == False and Auto_Init == False:\n",
    "            return\n",
    "        \n",
    "        os.mkdir(folder_path)\n",
    "        print(\"디렉토리를 만들었습니다 : \", folder_path)\n",
    "        gitignore(directory = folder_path)\n",
    "\n",
    "    os.chdir(folder_path)\n",
    "\n",
    "    if os.path.exists(net_name)== False and Auto_Init == False:\n",
    "            print(\"학습데이터 없음\")\n",
    "            os.chdir(\"../\")\n",
    "            return\n",
    "    \n",
    "    if net_reset == True or Data_Reset == True or (os.path.exists(net_name) == False and Auto_Init == True):\n",
    "    \n",
    "        model.train()\n",
    "        loss = []\n",
    "\n",
    "        criterion = nn.MSELoss()  # 평균 제곱 오차 (복원된 이미지와 원본 이미지 간의 차이)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for data in trainloader:\n",
    "                _, _, inputs, _ = data  # 레이블은 필요 없음\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                # 손상된 이미지 생성 (노이즈 추가)\n",
    "                noisy_inputs = inputs + 0.1 * torch.randn_like(inputs)\n",
    "                noisy_inputs = torch.clip(noisy_inputs, 0., 1.)  # 값이 0~1 사이로 유지되도록 조정\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 모델에 손상된 이미지 입력\n",
    "                outputs = model(noisy_inputs)\n",
    "                \n",
    "                # 손실 계산\n",
    "                loss = criterion(outputs, inputs)  # 원본 이미지와 복원된 이미지 간의 차이\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader)}')\n",
    "        \n",
    "\n",
    "        torch.save(model, net_name)\n",
    "        print(\"모델을 저장하였습니다 : \", net_name)\n",
    "        \n",
    "        if log_save == True or Data_Reset == True or (os.path.exists(net_name) == False and Auto_Init == True):\n",
    "            loss = loss.cpu()\n",
    "            np.save(log_name, loss.detach().numpy())\n",
    "            print(\"로그를 저장하였습니다 : \", log_name, \".npy\")\n",
    "        \n",
    "        print(os.getcwd())    \n",
    "        os.chdir(\"../\")\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return\n",
    "            \n",
    "        \n",
    "    else:      \n",
    "        if os.path.exists(log_name+\".npy\")== False:\n",
    "            print(\"accuracies 없음 (모델 로드 가능)\")\n",
    "            loss = []\n",
    "\n",
    "        else:  \n",
    "            loss = torch.from_numpy(np.load(log_name+\".npy\"))\n",
    "            print(\"loss 로드됨\")\n",
    "        \n",
    "        print(os.getcwd())\n",
    "        os.chdir(\"../\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jO8ldOZxpSWF"
   },
   "source": [
    "### 5. 데이터의 오염 통합 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    CIFAR-10 데이터셋에 다양한 공격을 추가하는 클래스입니다.\n",
    "\n",
    "    Attributes:\n",
    "    - dataset: 원본 데이터셋\n",
    "    - perbutationset : 오염 추가용 데이터셋 (CIFAR-100)\n",
    "    - attacked_ratio: 공격 비율\n",
    "    - label_attack: Label 오염 활성화 여부\n",
    "    - label_perterbation: Label 섭동 활성화 여부\n",
    "    - alpha: 이미지 겹침 공격의 혼합 비율\n",
    "    - partial_overlay: 이미지 부분 겹침 활성화 여부\n",
    "    - rotational_overlay: 이미지 회전 겹침 활성화 여부\n",
    "    - image_corruption: 이미지 결손 활성화 여부\n",
    "    - attack_order: 공격 순서 (\"label_first\" 또는 \"overlay_first\")\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, perterbationset, attacked_ratio=0.2, label_attack=True, label_perterbation = True, overlay=True, alpha=0.5, partial_overlay=True, rotational_overlay=True, image_corruption=True, corruption_ratio = 0.2, attack_order=\"label\", im_proc_order=\"overlay\"):\n",
    "        \"\"\" AugmentedDataset 객체를 초기화합니다. \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.perterbationset = perterbationset\n",
    "        self.attacked_ratio = attacked_ratio\n",
    "        self.label_attack = label_attack\n",
    "        self.label_perterbation = label_perterbation\n",
    "        self.overlay = overlay\n",
    "        self.alpha = alpha\n",
    "        self.partial_overlay = partial_overlay\n",
    "        self.rotational_overlay = rotational_overlay\n",
    "        self.image_corruption = image_corruption\n",
    "        self.corruption_ratio = corruption_ratio\n",
    "        self.attack_order = attack_order  # 공격 순서 설정\n",
    "        self.im_proc_order = im_proc_order\n",
    "\n",
    "        # 공격 인덱스 설정\n",
    "        self.attacked_indices = self._select_attacked_indices(self.attacked_ratio)\n",
    "\n",
    "        # Label 오염 생성 (라벨 공격이 활성화된 경우에만)\n",
    "        self.attacked_labels = self._crazy_labels() if self.label_attack else None\n",
    "        self.attacked_labels = self._label_flipper() if self.label_perterbation else None\n",
    "\n",
    "    def _select_attacked_indices(self, ratio):\n",
    "        \"\"\"공격 대상 샘플의 인덱스를 선택합니다.\"\"\"\n",
    "        num_attack_samples = int(ratio * len(self.dataset))\n",
    "        return random.sample(range(len(self.dataset)), num_attack_samples)\n",
    "\n",
    "    def _crazy_labels(self):\n",
    "        \"\"\"Label 오염된 라벨 리스트를 생성합니다.\"\"\"\n",
    "        attacked_labels = []\n",
    "        for idx in range(len(self.dataset)):\n",
    "            _, original_label = self.dataset[idx]\n",
    "            if idx in self.attacked_indices:\n",
    "                # 원래 라벨과 다른 무작위 라벨 생성\n",
    "                attacked_label = original_label\n",
    "                while attacked_label == original_label:\n",
    "                    attacked_label = random.randint(0, 9)\n",
    "                attacked_labels.append(attacked_label)\n",
    "            else:\n",
    "                attacked_labels.append(original_label)\n",
    "        return attacked_labels\n",
    "\n",
    "# Label Flipping을 샘플에 적용하는 함수 정의\n",
    "    def _label_flipper(self):\n",
    "        \"\"\"\n",
    "        CIFAR-10 데이터셋의 일부 샘플에 Label-Flipping오염을 가하는 함수입니다.\n",
    "        airplane : 0\n",
    "        automobile : 1\n",
    "        bird : 2\n",
    "        cat : 3\n",
    "        deer : 4\n",
    "        dog : 5\n",
    "        frog : 6\n",
    "        horse : 7\n",
    "        ship : 8\n",
    "        truck : 9\n",
    "\n",
    "        Automobile - Truck\n",
    "        Dog - Cat\n",
    "        Deer - Horse\n",
    "        Birds - Frog\n",
    "        Airplane - Ship\"\"\"\n",
    "        attacked_labels = []\n",
    "\n",
    "        for idx in range(len(self.dataset)):\n",
    "            # 이미지와 라벨을 가져오기\n",
    "            _, label = self.dataset[idx]\n",
    "\n",
    "            if idx in self.attacked_indices:\n",
    "                # 라벨 복사 후 공격 수행\n",
    "                original_label = label\n",
    "\n",
    "                if original_label == 1:\n",
    "                    label = 9\n",
    "                elif original_label == 9:\n",
    "                    label = 1\n",
    "                elif original_label == 5:\n",
    "                    label = 3\n",
    "                elif original_label == 3:\n",
    "                    label = 5\n",
    "                elif original_label == 7:\n",
    "                    label = 4\n",
    "                elif original_label == 4:\n",
    "                    label = 7\n",
    "                elif original_label == 2:\n",
    "                    label = 6\n",
    "                elif original_label == 6:\n",
    "                    label = 2\n",
    "                elif original_label == 0:\n",
    "                    label = 8\n",
    "                elif original_label == 8:\n",
    "                    label = 0\n",
    "            # 리스트에 추가\n",
    "            attacked_labels.append(label)\n",
    "\n",
    "        return attacked_labels\n",
    "\n",
    "    def _overlay(self, image, idx):\n",
    "        \"\"\"특정 이미지에 이미지 겹침 공격을 적용합니다.\"\"\"\n",
    "        if self.partial_overlay == False:\n",
    "            if idx in self.attacked_indices and self.overlay:\n",
    "                overlay_idx = random.randint(0, len(self.dataset) - 1)\n",
    "                overlay_image, _ = self.dataset[overlay_idx]\n",
    "                return (1 - self.alpha) * image + self.alpha * overlay_image\n",
    "            return image\n",
    "        \n",
    "        else:\n",
    "            if idx in self.attacked_indices:\n",
    "                # 텐서를 PIL 이미지로 변환\n",
    "                pil_image = transforms.ToPILImage()(image)\n",
    "\n",
    "                # 두 개의 이미지를 랜덤으로 선택하여 중첩\n",
    "                rand_idx_1 = random.randint(0, len(self.dataset) - 1)\n",
    "                rand_idx_2 = random.randint(0, len(self.dataset) - 1)\n",
    "\n",
    "                overlay_image_1, _ = self.dataset[rand_idx_1]\n",
    "                overlay_image_2, _ = self.dataset[rand_idx_2]\n",
    "\n",
    "                # 첫 번째 이미지를 중첩\n",
    "                overlay_h_1, overlay_w_1 = overlay_image_1.shape[1], overlay_image_1.shape[2]\n",
    "                scale_factor_1 = random.uniform(0.5, 1.0)\n",
    "                new_h_1 = int(overlay_h_1 * scale_factor_1)\n",
    "                new_w_1 = int(overlay_w_1 * scale_factor_1)\n",
    "\n",
    "                overlay_image_1_pil = transforms.ToPILImage()(overlay_image_1)\n",
    "                overlay_image_1_resized = overlay_image_1_pil.resize((new_w_1, new_h_1))\n",
    "\n",
    "                x1 = random.randint(0, pil_image.size[0] - new_w_1)\n",
    "                y1 = random.randint(0, pil_image.size[1] - new_h_1)\n",
    "                pil_image.paste(overlay_image_1_resized, (x1, y1))\n",
    "\n",
    "                # 두 번째 이미지를 중첩\n",
    "                overlay_h_2, overlay_w_2 = overlay_image_2.shape[1], overlay_image_2.shape[2]\n",
    "                scale_factor_2 = random.uniform(0.5, 1.0)\n",
    "                new_h_2 = int(overlay_h_2 * scale_factor_2)\n",
    "                new_w_2 = int(overlay_w_2 * scale_factor_2)\n",
    "\n",
    "                overlay_image_2_pil = transforms.ToPILImage()(overlay_image_2)\n",
    "                overlay_image_2_resized = overlay_image_2_pil.resize((new_w_2, new_h_2))\n",
    "\n",
    "                x2 = random.randint(0, pil_image.size[0] - new_w_2)\n",
    "                y2 = random.randint(0, pil_image.size[1] - new_h_2)\n",
    "                pil_image.paste(overlay_image_2_resized, (x2, y2))\n",
    "\n",
    "                # 여러 변형을 적용\n",
    "                final_image = pil_image.copy()\n",
    "                for _ in range(3):  # 세 번 변형 적용\n",
    "                    max_shift = 10  # 이동 범위 (픽셀 단위)\n",
    "                    shift_x = random.randint(-max_shift, max_shift)\n",
    "                    shift_y = random.randint(-max_shift, max_shift)\n",
    "                    transformed_image = final_image.transform(final_image.size, Image.AFFINE, (1, 0, shift_x, 0, 1, shift_y))\n",
    "\n",
    "                    # 크기 조정 (Resizing)\n",
    "                    resize_factor = random.uniform(0.5, 1.5)\n",
    "                    new_size = (int(transformed_image.size[0] * resize_factor), int(transformed_image.size[1] * resize_factor))\n",
    "                    transformed_image = transformed_image.resize(new_size)\n",
    "\n",
    "                    if self.rotational_overlay == True:\n",
    "                        # 회전 (Rotation)\n",
    "                        rotate_angle = random.randint(-30, 30)  # -30도에서 30도 사이로 회전\n",
    "                        transformed_image = transformed_image.rotate(rotate_angle)\n",
    "\n",
    "                    # 변형된 이미지를 원본 이미지에 중첩\n",
    "                    overlay_width, overlay_height = transformed_image.size\n",
    "                    max_x_offset = max(0, final_image.size[0] - overlay_width)\n",
    "                    max_y_offset = max(0, final_image.size[1] - overlay_height)\n",
    "\n",
    "                    x_offset = random.randint(0, max_x_offset)\n",
    "                    y_offset = random.randint(0, max_y_offset)\n",
    "\n",
    "                    # 중첩\n",
    "                    if transformed_image.mode == 'RGBA':\n",
    "                        final_image.paste(transformed_image, (x_offset, y_offset), transformed_image.split()[3])  # 알파 채널 처리\n",
    "                    else:\n",
    "                        final_image.paste(transformed_image, (x_offset, y_offset))\n",
    "                    # 최종 이미지를 텐서로 변환하여 저장\n",
    "\n",
    "                return transforms.ToTensor()(final_image)\n",
    "                    \n",
    "            return image  # 이미지가 공격되지 않으면 원본 이미지 그대로 반환\n",
    "\n",
    "    # 1. 결손 처리 함수 수정\n",
    "    def _corrupt_image(self, image, idx):\n",
    "        \"\"\"이미지의 일부 픽셀을 결손 처리합니다.\"\"\"\n",
    "        if self.image_corruption == True:\n",
    "            if idx in self.attacked_indices and self.overlay:\n",
    "\n",
    "                image_np = image.numpy()  # 텐서를 NumPy 배열로 변환\n",
    "                total_pixels = image_np.size\n",
    "                num_corrupted_pixels = int(total_pixels * self.corruption_ratio)\n",
    "\n",
    "                # 랜덤으로 픽셀 선택 (이미지의 플랫(flat) 배열에서 인덱스 기준)\n",
    "                indices = random.sample(range(total_pixels), num_corrupted_pixels)\n",
    "                flat_image = image_np.flatten()\n",
    "\n",
    "                # 선택된 픽셀을 0으로 설정\n",
    "                flat_image[indices] = 0\n",
    "\n",
    "                # 이미지를 원래 형태로 복원\n",
    "                image_np = flat_image.reshape(image_np.shape)\n",
    "                return torch.tensor(image_np)\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"데이터셋의 전체 길이를 반환합니다.\"\"\"\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __image_process__(self, image, idx):\n",
    "        \"\"\" Image Processing 순서함수\"\"\"\n",
    "        if self.im_proc_order == \"overlay\":\n",
    "            image = self._overlay(image, idx)\n",
    "            image = self._corrupt_image(image, idx)\n",
    "        elif self.im_proc_order == \"corrupt\":\n",
    "            image = self._overlay(image, idx)\n",
    "            image = self._corrupt_image(image, idx)\n",
    "        else:       \n",
    "            raise ValueError(f\"Invalid im_proc_order: {self.im_proc_order}. Use 'overlay' or 'corrupt'.\")\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        데이터셋의 특정 샘플을 반환합니다.\n",
    "\n",
    "        Args:\n",
    "        - idx: 샘플 인덱스\n",
    "\n",
    "        Returns:\n",
    "        - (Tensor, int): 이미지 텐서와 라벨\n",
    "        \"\"\"\n",
    "        # 원본 이미지와 라벨 가져오기\n",
    "        image, original_label = self.dataset[idx]\n",
    "\n",
    "        if self.attack_order == \"label\":\n",
    "            # 라벨 오염 -> 이미지 겹침\n",
    "            label = self.attacked_labels[idx] if self.label_attack else original_label\n",
    "            image = self.__image_process__(image, idx)\n",
    "\n",
    "\n",
    "        elif self.attack_order == \"overlay\":\n",
    "            # 이미지 겹침 -> 라벨 오염\n",
    "            image = self.__image_process__(image, idx)\n",
    "            label = self.attacked_labels[idx] if self.label_attack else original_label\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid attack order: {self.attack_order}. Use 'label' or 'overlay'.\")\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSiPtDKiepI3"
   },
   "source": [
    "### 실험 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3aQ0bpZHR5I"
   },
   "source": [
    "##### 1. 오염 없는 일반적 데이터 학습 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3GLSYPA4eyoh"
   },
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_res = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1V7XTDue2uB",
    "outputId": "f163034d-66a5-4936-a8a2-460cdaa4d862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data Type: 2\n",
      "[Epoch 1] loss: 1.587\n",
      "Accuracy: 55.61%\n",
      "[Epoch 2] loss: 1.239\n",
      "Accuracy: 61.94%\n",
      "모델을 저장하였습니다 :  default_resnet.pt\n",
      "로그를 저장하였습니다 :  default_log .npy\n",
      "c:\\Users\\eaton\\Desktop\\Capstone 2\\code\\default_path\n"
     ]
    }
   ],
   "source": [
    "acc_res = train_and_evaluate(model_res, train_loader, test_loader, net_name=\"default_resnet.pt\", log_name = \"default_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rMHgoh4HZAS"
   },
   "source": [
    "##### 2. 오염을 적용하는 데이터 학습 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sGUuW6b4QhTX"
   },
   "outputs": [],
   "source": [
    "train_set_attacked = AugmentedDataset(\n",
    "    dataset=train_set,\n",
    "    perterbationset=add_set,\n",
    "    attacked_ratio=0.4,\n",
    "    overlay=True,\n",
    "    alpha=0.5,\n",
    "    label_attack=True,\n",
    "    partial_overlay=True,\n",
    "    corruption_ratio=0.2,\n",
    "    attack_order=\"label\",\n",
    "    im_proc_order=\"overlay\"\n",
    ")\n",
    "\n",
    "train_loader_attacked = DataLoader(dataset=train_set_attacked, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jDnonxr_x5OE"
   },
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_res_1 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AcScGlNrQfXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data Type: 2\n",
      "[Epoch 1] loss: 2.016\n",
      "Accuracy: 37.58%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc_res_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_res_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_attacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_loader_attacked.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_loader_attacked\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 42\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_loader, test_loader, device, epochs, Data_Reset, net_reset, folder_path, net_name, log_save, log_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_items \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 42\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moriginal_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eaton\\Desktop\\Capstone 2\\code\\.egpu\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\eaton\\Desktop\\Capstone 2\\code\\.egpu\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\eaton\\Desktop\\Capstone 2\\code\\.egpu\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\eaton\\Desktop\\Capstone 2\\code\\.egpu\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[15], line 250\u001b[0m, in \u001b[0;36mAugmentedDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m데이터셋의 특정 샘플을 반환합니다.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m- (Tensor, int): 이미지 텐서와 라벨\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# 원본 이미지와 라벨 가져오기\u001b[39;00m\n\u001b[1;32m--> 250\u001b[0m image, original_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# 라벨 오염 -> 이미지 겹침\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattacked_labels[idx] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_attack \u001b[38;5;28;01melse\u001b[39;00m original_label\n",
      "File \u001b[1;32mc:\\Users\\eaton\\Desktop\\Capstone 2\\code\\.egpu\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\eaton\\Desktop\\Capstone 2\\code\\.egpu\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\eaton\\Desktop\\Capstone 2\\code\\.egpu\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eaton\\Desktop\\Capstone 2\\code\\.egpu\\Lib\\site-packages\\torchvision\\transforms\\functional.py:176\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    174\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_res_1 = train_and_evaluate(model_res_1, train_loader_attacked, test_loader, net_name=\"train_loader_attacked.pt\", log_name = \"train_loader_attacked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLWohjWieuJV"
   },
   "source": [
    "### 최종 비교 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "eWk22manS-sn",
    "outputId": "fbc2095f-1e0d-4395-d018-b084ad37bd81"
   },
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='ResNet_op')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "id": "AWQVUQLDyb_2",
    "outputId": "fe9cdfaa-6572-4bb1-c625-a878d5689932"
   },
   "outputs": [],
   "source": [
    "visualize_multiple_dataloaders([train_loader, train_loader_attacked, train_loader_attacked, train_loader_attacked, train_loader_attacked], test_loader, images_per_loader=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poison Activation Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_attacker_test =  AugmentedDataset(\n",
    "    dataset=train_set,\n",
    "    perterbationset=add_set,\n",
    "    attacked_ratio=0.4,\n",
    "    overlay=True,\n",
    "    alpha=0.5,\n",
    "    label_attack=True,\n",
    "    partial_overlay=True,\n",
    "    corruption_ratio=0.2,\n",
    "    attack_order=\"label\",\n",
    "    im_proc_order=\"overlay\"\n",
    ")\n",
    "\n",
    "attacker_test = DataLoader(dataset=train_set_attacker_test, batch_size=64, shuffle=True)\n",
    "\n",
    "visualize_multiple_dataloaders([train_loader, attacker_test, attacker_test, attacker_test, attacker_test], test_loader, images_per_loader=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Image Restoration Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 중독데이터 복원 AI 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CIFAR-10을 학습데이터로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_10 = Autoencoder().to(device)\n",
    "unet_10 = UNet().to(device)\n",
    "\n",
    "Autotest = train_model(auto_10, train_loader, net_name=\"auto_10.pt\", log_name = \"auto_10\")\n",
    "unettest = train_model(unet_10, train_loader, net_name=\"unet_10.pt\", log_name = \"unet_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 중독데이터를 학습데이터로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_attacked = Autoencoder().to(device)\n",
    "unet_attacked = UNet().to(device)\n",
    "\n",
    "Autotest_attaked = train_model(auto_attacked, train_loader_attacked, net_name=\"auto_attacked.pt\", log_name = \"auto_attacked\")\n",
    "unettest_attaked = train_model(unet_attacked, train_loader_attacked, net_name=\"unet_attacked.pt\", log_name = \"unet_attacked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CIFAR-100을 학습데이터로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_100 = Autoencoder().to(device)\n",
    "unet_100 = UNet().to(device)\n",
    "\n",
    "Autotest_100 = train_model(auto_100, add_loader, net_name=\"auto_100.pt\", log_name = \"auto_100\")\n",
    "unettest_100 = train_model(unet_100, add_loader, net_name=\"unet_100.pt\", log_name = \"unet_100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 학습결과 표출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 결과 확인 함수\n",
    "def show_images(original, label, output):\n",
    "    # 결과 이미지를 시각화\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax[0].imshow(original.permute(1, 2, 0).cpu().detach().numpy())\n",
    "    ax[0].set_title('Original')\n",
    "    ax[1].imshow(output.permute(1, 2, 0).cpu().detach().numpy())\n",
    "    ax[1].set_title('Recovered Output')\n",
    "    \n",
    "    plt.show()\n",
    "    print(label)\n",
    "\n",
    "def multi_show(input, label, output, sample = 10):\n",
    "    for i in range(sample):\n",
    "        index = random.randrange(1, len(label))\n",
    "        show_images(input[index], label[index], output[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 중독된 데이터 복구 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 복구데이터 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10WithModelOutputAndLabels(Dataset):\n",
    "    def __init__(self, original_images, original_labels, poisoned_images,  poisoned_labels, restored_images):\n",
    "        self.original_images= original_images\n",
    "        self.original_labels = original_labels        \n",
    "        self.poisoned_images = poisoned_images\n",
    "        self.poisoned_labels = poisoned_labels\n",
    "        self.restored_images = restored_images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.poisoned_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.original_images[idx], self.original_labels[idx], self.poisoned_images[idx], self.poisoned_labels[idx] , self.restored_images[idx]\n",
    "\n",
    "# 이미지를 모델에 통과시키고 출력 저장하는 함수\n",
    "def process_and_save_cifar10(dataloader, net_name =\"default_net.pt\" , output_filename=\"processed_cifar10_with_labels.pth\"):\n",
    "    \"\"\"\n",
    "    CIFAR-10 DataLoader에서 이미지를 처리하고, 모델의 출력과 라벨을 저장하는 함수.\n",
    "    \"\"\"\n",
    "    os.chdir(default_path)\n",
    "    model = torch.load(net_name)\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "    all_original_images =[]\n",
    "    all_original_labels=[]\n",
    "    all_images = []\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # 예측 시에는 그래디언트 계산을 하지 않음\n",
    "        for data in dataloader:\n",
    "            original_images, original_labels, images, labels = data\n",
    "            # 이미지를 GPU로 이동 (GPU가 사용 가능하면)\n",
    "            images = images.cuda() if torch.cuda.is_available() else images\n",
    "            labels = labels.cuda() if torch.cuda.is_available() else labels\n",
    "\n",
    "            # 모델을 통해 예측 결과 얻기\n",
    "            outputs = model(images)\n",
    "\n",
    "            # 결과를 리스트에 추가\n",
    "            all_original_images.append(original_images)\n",
    "            all_original_labels.append(original_labels)\n",
    "            all_images.append(images.cpu())  # CPU로 이동하여 저장\n",
    "            all_labels.append(labels.cpu())  # CPU로 이동하여 저장\n",
    "            all_outputs.append(outputs.cpu())  # CPU로 이동하여 저장\n",
    "\n",
    "    # CIFAR-10 이미지, 모델 출력, 라벨을 포함한 Dataset 생성\n",
    "    combined_dataset = CIFAR10WithModelOutputAndLabels(\n",
    "        torch.cat(all_original_images), torch.cat(all_original_labels), torch.cat(all_images), torch.cat(all_labels) , torch.cat(all_outputs)\n",
    "    )\n",
    "\n",
    "    os.chdir(default_path)\n",
    "    # PyTorch Dataset을 저장\n",
    "    torch.save(combined_dataset, output_filename)\n",
    "    print(f\"Processed data with labels saved to {output_filename}\")\n",
    "    print(os.getcwd)\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 복구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_10\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, net_name = \"auto_10.pt\", output_filename=\"auto_10.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "os.chdir(default_path)\n",
    "s_auto_10 = torch.load(\"auto_10.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "o_images, o_labels, images, labels , outputs=s_auto_10.original_images, s_auto_10.original_labels, s_auto_10.poisoned_images, s_auto_10.poisoned_labels, s_auto_10.restored_images\n",
    "\n",
    "multi_show(images, labels, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet_10\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, net_name = \"unet_10.pt\", output_filename=\"unet_10.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "os.chdir(default_path)\n",
    "s_unet_10 = torch.load(\"unet_10.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "images, outputs, labels = s_unet_10.original_data, s_unet_10.model_outputs, s_unet_10.labels\n",
    "\n",
    "multi_show(images, outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_attack\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, net_name = \"auto_attacked.pt\", output_filename=\"auto_attacked.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "os.chdir(default_path)\n",
    "s_auto_attacked = torch.load(\"auto_attacked.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "images, outputs, labels = s_auto_attacked.original_data, s_auto_attacked.model_outputs, s_auto_attacked.labels\n",
    "\n",
    "multi_show(images, outputs, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet_attack\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, net_name = \"unet_attacked.pt\", output_filename=\"unet_attacked.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "os.chdir(default_path)\n",
    "s_unet_attacked = torch.load(\"unet_attacked.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "images, outputs, labels = s_unet_attacked.original_data, s_unet_attacked.model_outputs, s_unet_attacked.labels\n",
    "\n",
    "multi_show(images, outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_100\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, net_name = \"auto_100.pt\", output_filename=\"auto_100.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "os.chdir(default_path)\n",
    "s_auto_100 = torch.load(\"auto_100.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "images, outputs, labels = s_auto_100.original_data, s_auto_100.model_outputs, s_auto_100.labels\n",
    "\n",
    "multi_show(images, outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet_100\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, net_name = \"unet_100.pt\", output_filename=\"unet_100.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "os.chdir(default_path)\n",
    "s_unet_100 = torch.load(\"unet_100.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "images, outputs, labels = s_unet_100.original_data, s_unet_100.model_outputs, s_unet_100.labels\n",
    "\n",
    "multi_show(images, outputs, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 복원 이미지 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_auto_10 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "model_unet_10 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "\n",
    "model_auto_attack = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "model_unet_attack = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "\n",
    "model_auto_100 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "model_unet_100 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_10 = DataLoader(dataset=s_auto_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_10 = train_and_evaluate(model_auto_10, train_loader_auto_10, test_loader, net_name=\"auto_10_7.pt\", log_name = \"auto_10_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_10 = DataLoader(dataset=s_unet_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_10 = train_and_evaluate(model_unet_10, train_loader_unet_10, test_loader, net_name=\"unet_10_7.pt\", log_name = \"unet_10_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_attack = DataLoader(dataset=s_auto_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_attack = train_and_evaluate(model_auto_attack, train_loader_auto_attack, test_loader, net_name=\"auto_attacked_7.pt\", log_name = \"auto_attacked_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_attack = DataLoader(dataset=s_unet_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_attack = train_and_evaluate(model_unet_attack, train_loader_unet_attack, test_loader, net_name=\"unet_attacked_7.pt\", log_name = \"unet_attacked_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_100 = DataLoader(dataset=s_auto_100, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_100 = train_and_evaluate(model_auto_100, train_loader_auto_100, test_loader, net_name=\"auto_100_7.pt\", log_name = \"auto_100_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_100 = DataLoader(dataset=s_unet_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_100 = train_and_evaluate(model_unet_100, train_loader_unet_100, test_loader, net_name=\"unet_100_7.pt\", log_name = \"unet_100_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='Poisoned')\n",
    "plt.plot(acc_auto_10, marker='x', linestyle='-', markersize=5, label='auto_10')\n",
    "plt.plot(acc_unet_10, marker='x', linestyle='-', markersize=5, label='unet_10')\n",
    "plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='auto_attack')\n",
    "plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='unet_attack')\n",
    "plt.plot(acc_auto_100, marker='x', linestyle='-', markersize=5, label='auto_100')\n",
    "plt.plot(acc_unet_100, marker='x', linestyle='-', markersize=5, label='unet_100')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Classification Multiplied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_auto_10_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)\n",
    "model_unet_10_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)\n",
    "\n",
    "model_auto_attack_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)\n",
    "model_unet_attack_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)\n",
    "\n",
    "model_auto_100_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)\n",
    "model_unet_100_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_auto_10_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)\n",
    "model_unet_10_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)\n",
    "\n",
    "model_auto_attack_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)\n",
    "model_unet_attack_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)\n",
    "\n",
    "model_auto_100_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)\n",
    "model_unet_100_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_auto_10_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)\n",
    "model_unet_10_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)\n",
    "\n",
    "model_auto_attack_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)\n",
    "model_unet_attack_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)\n",
    "\n",
    "model_auto_100_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)\n",
    "model_unet_100_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_auto_10_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)\n",
    "model_unet_10_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)\n",
    "\n",
    "model_auto_attack_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)\n",
    "model_unet_attack_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)\n",
    "\n",
    "model_auto_100_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)\n",
    "model_unet_100_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_10_2x = DataLoader(dataset=s_auto_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_10_2x = train_and_evaluate(model_auto_10_2x, train_loader_auto_10_2x, test_loader, net_name=\"auto_10_2x.pt\", log_name = \"auto_10_2x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_10_3x = DataLoader(dataset=s_auto_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_10_3x = train_and_evaluate(model_auto_10_3x, train_loader_auto_10_3x, test_loader, net_name=\"auto_10_7.3x\", log_name = \"auto_10_3x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_10_5x = DataLoader(dataset=s_auto_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_10_5x = train_and_evaluate(model_auto_10_5x, train_loader_auto_10_5x, test_loader, net_name=\"auto_attacked_5x.pt\", log_name = \"auto_attacked_10x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_10_10x = DataLoader(dataset=s_auto_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_10_10x = train_and_evaluate(model_auto_10_10x, train_loader_auto_10_10x, test_loader, net_name=\"auto_10_10x.pt\", log_name = \"auto_10_10x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='Poisoned')\n",
    "plt.plot(acc_auto_10, marker='x', linestyle='-', markersize=5, label='auto_10')\n",
    "plt.plot(acc_auto_10_2x, marker='+', linestyle='-', markersize=5, label='auto_10_2x')\n",
    "plt.plot(acc_auto_10_3x, marker='+', linestyle='-', markersize=5, label='auto_10_3x')\n",
    "plt.plot(acc_auto_10_5x, marker='+', linestyle='-', markersize=5, label='auto_10_5x')\n",
    "plt.plot(acc_auto_10_10x, marker='+', linestyle='-', markersize=5, label='auto_10_10x')\n",
    "# plt.plot(acc_unet_10, marker='x', linestyle='-', markersize=5, label='unet_10')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='auto_attack')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='unet_attack')\n",
    "# plt.plot(acc_auto_100, marker='x', linestyle='-', markersize=5, label='auto_100')\n",
    "# plt.plot(acc_unet_100, marker='x', linestyle='-', markersize=5, label='unet_100')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "kSD6sI1ojEfo",
    "Nc6NvqDWjJjl",
    "UVF7GSn9jOB5",
    "M5haTn0vlaFa",
    "tLWohjWieuJV"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".egpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

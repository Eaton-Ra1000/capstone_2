{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgnERK0iT7U_"
   },
   "source": [
    "### 함수 저장소\n",
    "\n",
    "1. 학습 데이터셋 비교 가시화\n",
    "\n",
    "visualize_multiple_dataloaders([test_loader], test_loader, images_per_loader=5)\n",
    "\n",
    "2. 실험 진행용 학습모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSD6sI1ojEfo"
   },
   "source": [
    "### 1. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K0k8rocQiudv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLjVNkuKCpcG",
    "outputId": "5ed1d8c3-224d-47b4-cf51-c229da4eb7b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nc6NvqDWjJjl"
   },
   "source": [
    "### 2. 데이터셋 정의 - 비오염"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n93dhuI8kEqb"
   },
   "outputs": [],
   "source": [
    "# Data loading and transformations\n",
    "transform = transforms.Compose([\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.RandomCrop(32, padding=4),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1YfR7U4CCn_",
    "outputId": "b2ca1462-5373-4ef9-ef4c-b8be73959186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Use PyTorch's torchvision.transforms.ToTenesor() to convert the dataset to tensor format\n",
    "train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "add_set = CIFAR100(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Iv1xifZj_B5Q"
   },
   "outputs": [],
   "source": [
    "# Use PyTorch's DataLoader to divide the dataset into mini-batches and load the data\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=False)\n",
    "add_loader = DataLoader(dataset=add_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eYGOwI2lrw3l"
   },
   "outputs": [],
   "source": [
    "def visualize_multiple_dataloaders(dataloaders, trainloader, images_per_loader=5):\n",
    "    num_loaders = len(dataloaders)\n",
    "    classes = trainloader.dataset.classes\n",
    "\n",
    "    # 플롯 크기 설정\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    for i, loader in enumerate(dataloaders):\n",
    "        # 각 DataLoader에서 배치 하나 가져오기\n",
    "        batch = next(iter(loader))\n",
    "        images, labels = batch\n",
    "        images = torch.clamp(images, 0, 1)  # 이미지를 0과 1 사이로 클리핑하여 표시 문제 방지\n",
    "\n",
    "        # 각 DataLoader에서 선택한 이미지 수만큼 시각화\n",
    "        for j in range(images_per_loader):\n",
    "            idx = i * images_per_loader + j\n",
    "            plt.subplot(num_loaders, images_per_loader, idx + 1)\n",
    "            plt.imshow(images[j].permute(1, 2, 0))  # 이미지 차원 변경: (C, H, W) -> (H, W, C)\n",
    "            plt.title(classes[labels[j].item()])\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVF7GSn9jOB5"
   },
   "source": [
    "### 3. 신경망 코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YxUFFR4Akpau"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Autoencoder 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder 부분\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),   # 32x32 -> 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # 16x16 -> 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1), # 8x8 -> 4x4\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128)  # latent space (압축된 표현)\n",
    "        )\n",
    "        \n",
    "        # Decoder 부분\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256 * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (256, 4, 4)),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1), # 4x4 -> 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),   # 8x8 -> 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),     # 16x16 -> 32x32\n",
    "            nn.Tanh()  # 0~1 범위로 출력\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. U-Net 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # 인코더 (Contracting Path)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # 32x32 -> 16x16\n",
    "        )\n",
    "        \n",
    "        self.encoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # 16x16 -> 8x8\n",
    "        )\n",
    "        \n",
    "        self.encoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # 8x8 -> 4x4\n",
    "        )\n",
    "\n",
    "        # 병목층 (Bottleneck)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 디코더 (Expanding Path)\n",
    "        self.decoder_1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')  # 4x4 -> 8x8\n",
    "        )\n",
    "        \n",
    "        self.decoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')  # 8x8 -> 16x16\n",
    "        )\n",
    "        \n",
    "        self.decoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')  # 16x16 -> 32x32\n",
    "        )\n",
    "        \n",
    "        # 최종 출력 레이어\n",
    "        self.final_conv = nn.Conv2d(64, 3, kernel_size=3, padding=1)  # 출력 채널 3 (RGB 이미지)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 인코더\n",
    "        enc1 = self.encoder(x)\n",
    "        enc2 = self.encoder_2(enc1)\n",
    "        enc3 = self.encoder_3(enc2)\n",
    "        \n",
    "        # 병목층\n",
    "        bottleneck = self.bottleneck(enc3)\n",
    "        \n",
    "        # 디코더\n",
    "        dec1 = self.decoder_1(bottleneck)\n",
    "        dec2 = self.decoder_2(dec1)\n",
    "        dec3 = self.decoder_3(dec2)\n",
    "        \n",
    "        # 최종 출력\n",
    "        out = self.final_conv(dec3)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5haTn0vlaFa"
   },
   "source": [
    "### 4. 신경망 학습과 테스트 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XJD8q_BHlfkv"
   },
   "outputs": [],
   "source": [
    "# Evaluate function\n",
    "def evaluate(model, device, test_loader):\n",
    "  model.eval()\n",
    "  total_correct = 0\n",
    "  with torch.no_grad():\n",
    "     for data, target in test_loader:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      output = model(data)\n",
    "      _, preds = torch.max(output, 1)\n",
    "      total_correct += (preds == target).sum().item()\n",
    "\n",
    "  accuracy = 100 * total_correct / len(test_loader.dataset)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yJhbIRtSqUIN"
   },
   "outputs": [],
   "source": [
    "# Train and evaluate function\n",
    "def train_and_evaluate(model, device, train_loader, test_loader, epochs=5):\n",
    "  model.train()\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "  optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "  accuracies = []\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    data_iterator = iter(train_loader)\n",
    "    for inputs, labels in data_iterator:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'[Epoch {epoch + 1}] loss: {running_loss / len(train_loader):.3f}')\n",
    "\n",
    "    accuracy = evaluate(model, device, test_loader)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "  return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def train_model(model, trainloader, epochs=5):\n",
    "    model.train()\n",
    "\n",
    "    criterion = nn.MSELoss()  # 평균 제곱 오차 (복원된 이미지와 원본 이미지 간의 차이)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in trainloader:\n",
    "            inputs, _ = data  # 레이블은 필요 없음\n",
    "            inputs = inputs.cuda()\n",
    "\n",
    "            # 손상된 이미지 생성 (노이즈 추가)\n",
    "            noisy_inputs = inputs + 0.1 * torch.randn_like(inputs)\n",
    "            noisy_inputs = torch.clip(noisy_inputs, 0., 1.)  # 값이 0~1 사이로 유지되도록 조정\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델에 손상된 이미지 입력\n",
    "            outputs = model(noisy_inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, inputs)  # 원본 이미지와 복원된 이미지 간의 차이\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def train_model(model, trainloader, epochs=5):\n",
    "    model.train()\n",
    "\n",
    "    criterion = nn.MSELoss()  # 평균 제곱 오차 (복원된 이미지와 원본 이미지 간의 차이)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in trainloader:\n",
    "            inputs, _ = data  # 레이블은 필요 없음\n",
    "            inputs = inputs.cuda()\n",
    "\n",
    "            # 손상된 이미지 생성 (노이즈 추가)\n",
    "            noisy_inputs = inputs + 0.1 * torch.randn_like(inputs)\n",
    "            noisy_inputs = torch.clip(noisy_inputs, 0., 1.)  # 값이 0~1 사이로 유지되도록 조정\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델에 손상된 이미지 입력\n",
    "            outputs = model(noisy_inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, inputs)  # 원본 이미지와 복원된 이미지 간의 차이\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate function\n",
    "def train_and_evaluate_after(model, device, train_loader, test_loader, epochs=5):\n",
    "    model.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        data_iterator = iter(train_loader)\n",
    "        \n",
    "        # train_loader에서 반환되는 값이 3개일 경우 (inputs, model_outputs, labels)\n",
    "        for inputs, model_outputs, labels in data_iterator:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'[Epoch {epoch + 1}] loss: {running_loss / len(train_loader):.3f}')\n",
    "\n",
    "        # 테스트\n",
    "        accuracy = evaluate(model, device, test_loader)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jO8ldOZxpSWF"
   },
   "source": [
    "### 5. 데이터의 오염 통합 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aCfVW3PELFVe"
   },
   "outputs": [],
   "source": [
    "class AugmentedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    CIFAR-10 데이터셋에 다양한 공격을 추가하는 클래스입니다.\n",
    "\n",
    "    Attributes:\n",
    "    - dataset: 원본 데이터셋\n",
    "    - perbutationset : 오염 추가용 데이터셋 (CIFAR-100)\n",
    "    - attacked_ratio: 공격 비율\n",
    "    - label_attack: Label 오염 활성화 여부\n",
    "    - label_perterbation: Label 섭동 활성화 여부\n",
    "    - alpha: 이미지 겹침 공격의 혼합 비율\n",
    "    - partial_overlay: 이미지 부분 겹침 활성화 여부\n",
    "    - rotational_overlay: 이미지 회전 겹침 활성화 여부\n",
    "    - image_corruption: 이미지 결손 활성화 여부\n",
    "    - attack_order: 공격 순서 (\"label_first\" 또는 \"overlay_first\")\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, perterbationset, attacked_ratio=0.2, label_attack=True, label_perterbation = True, overlay=True, alpha=0.5, partial_overlay=True, rotational_overlay=True, image_corruption=True, attack_order=\"label_first\"):\n",
    "        \"\"\" AugmentedDataset 객체를 초기화합니다. \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.perterbationset = perterbationset\n",
    "        self.attacked_ratio = attacked_ratio\n",
    "        self.label_attack = label_attack\n",
    "        self.label_perterbation = label_perterbation\n",
    "        self.overlay = overlay\n",
    "        self.alpha = alpha\n",
    "        self.partial_overlay = partial_overlay\n",
    "        self.rotational_overlay = rotational_overlay\n",
    "        self.image_corruption = image_corruption\n",
    "        self.attack_order = attack_order  # 공격 순서 설정\n",
    "\n",
    "        # 공격 인덱스 설정\n",
    "        self.attacked_indices = self._select_attacked_indices(self.attacked_ratio)\n",
    "\n",
    "        # Label 오염 생성 (라벨 공격이 활성화된 경우에만)\n",
    "        self.attacked_labels = self._crazy_labels() if self.label_attack else None\n",
    "        self.attacked_labels = self._label_flipper() if self.label_perterbation else None\n",
    "\n",
    "    def _select_attacked_indices(self, ratio):\n",
    "        \"\"\"공격 대상 샘플의 인덱스를 선택합니다.\"\"\"\n",
    "        num_attack_samples = int(ratio * len(self.dataset))\n",
    "        return random.sample(range(len(self.dataset)), num_attack_samples)\n",
    "\n",
    "    def _crazy_labels(self):\n",
    "        \"\"\"Label 오염된 라벨 리스트를 생성합니다.\"\"\"\n",
    "        attacked_labels = []\n",
    "        for idx in range(len(self.dataset)):\n",
    "            _, original_label = self.dataset[idx]\n",
    "            if idx in self.attacked_indices:\n",
    "                # 원래 라벨과 다른 무작위 라벨 생성\n",
    "                attacked_label = original_label\n",
    "                while attacked_label == original_label:\n",
    "                    attacked_label = random.randint(0, 9)\n",
    "                attacked_labels.append(attacked_label)\n",
    "            else:\n",
    "                attacked_labels.append(original_label)\n",
    "        return attacked_labels\n",
    "\n",
    "# Label 오염을 10%의 샘플에 적용하는 함수 정의\n",
    "    def _label_flipper(self):\n",
    "        \"\"\"\n",
    "        CIFAR-10 데이터셋의 일부 샘플에 Label-Flipping오염을 가하는 함수입니다.\n",
    "        airplane : 0\n",
    "        automobile : 1\n",
    "        bird : 2\n",
    "        cat : 3\n",
    "        deer : 4\n",
    "        dog : 5\n",
    "        frog : 6\n",
    "        horse : 7\n",
    "        ship : 8\n",
    "        truck : 9\n",
    "\n",
    "        Automobile - Truck\n",
    "        Dog - Cat\n",
    "        Deer - Horse\n",
    "        Birds - Frog\n",
    "        Airplane - Ship\"\"\"\n",
    "        attacked_labels = []\n",
    "\n",
    "        for idx in range(len(self.dataset)):\n",
    "            # 이미지와 라벨을 가져오기\n",
    "            _, label = self.dataset[idx]\n",
    "\n",
    "            if idx in self.attacked_indices:\n",
    "                # 라벨 복사 후 공격 수행\n",
    "                original_label = label\n",
    "\n",
    "                if original_label == 1:\n",
    "                    label = 9\n",
    "                elif original_label == 9:\n",
    "                    label = 1\n",
    "                elif original_label == 5:\n",
    "                    label = 3\n",
    "                elif original_label == 3:\n",
    "                    label = 5\n",
    "                elif original_label == 7:\n",
    "                    label = 4\n",
    "                elif original_label == 4:\n",
    "                    label = 7\n",
    "                elif original_label == 2:\n",
    "                    label = 6\n",
    "                elif original_label == 6:\n",
    "                    label = 2\n",
    "                elif original_label == 0:\n",
    "                    label = 8\n",
    "                elif original_label == 8:\n",
    "                    label = 0\n",
    "            # 리스트에 추가\n",
    "            attacked_labels.append(label)\n",
    "\n",
    "        return attacked_labels\n",
    "\n",
    "    def _overlay(self, image, idx):\n",
    "        \"\"\"특정 이미지에 이미지 겹침 공격을 적용합니다.\"\"\"\n",
    "        if self.partial_overlay == False:\n",
    "            if idx in self.attacked_indices and self.overlay:\n",
    "                overlay_idx = random.randint(0, len(self.dataset) - 1)\n",
    "                overlay_image, _ = self.dataset[overlay_idx]\n",
    "                return (1 - self.alpha) * image + self.alpha * overlay_image\n",
    "            return image\n",
    "        \n",
    "        else:\n",
    "            if idx in self.attacked_indices:\n",
    "                # 텐서를 PIL 이미지로 변환\n",
    "                pil_image = transforms.ToPILImage()(image)\n",
    "\n",
    "                # 두 개의 이미지를 랜덤으로 선택하여 중첩\n",
    "                rand_idx_1 = random.randint(0, len(self.dataset) - 1)\n",
    "                rand_idx_2 = random.randint(0, len(self.dataset) - 1)\n",
    "\n",
    "                overlay_image_1, _ = self.dataset[rand_idx_1]\n",
    "                overlay_image_2, _ = self.dataset[rand_idx_2]\n",
    "\n",
    "                # 첫 번째 이미지를 중첩\n",
    "                overlay_h_1, overlay_w_1 = overlay_image_1.shape[1], overlay_image_1.shape[2]\n",
    "                scale_factor_1 = random.uniform(0.5, 1.0)\n",
    "                new_h_1 = int(overlay_h_1 * scale_factor_1)\n",
    "                new_w_1 = int(overlay_w_1 * scale_factor_1)\n",
    "\n",
    "                overlay_image_1_pil = transforms.ToPILImage()(overlay_image_1)\n",
    "                overlay_image_1_resized = overlay_image_1_pil.resize((new_w_1, new_h_1))\n",
    "\n",
    "                x1 = random.randint(0, pil_image.size[0] - new_w_1)\n",
    "                y1 = random.randint(0, pil_image.size[1] - new_h_1)\n",
    "                pil_image.paste(overlay_image_1_resized, (x1, y1))\n",
    "\n",
    "                # 두 번째 이미지를 중첩\n",
    "                overlay_h_2, overlay_w_2 = overlay_image_2.shape[1], overlay_image_2.shape[2]\n",
    "                scale_factor_2 = random.uniform(0.5, 1.0)\n",
    "                new_h_2 = int(overlay_h_2 * scale_factor_2)\n",
    "                new_w_2 = int(overlay_w_2 * scale_factor_2)\n",
    "\n",
    "                overlay_image_2_pil = transforms.ToPILImage()(overlay_image_2)\n",
    "                overlay_image_2_resized = overlay_image_2_pil.resize((new_w_2, new_h_2))\n",
    "\n",
    "                x2 = random.randint(0, pil_image.size[0] - new_w_2)\n",
    "                y2 = random.randint(0, pil_image.size[1] - new_h_2)\n",
    "                pil_image.paste(overlay_image_2_resized, (x2, y2))\n",
    "\n",
    "                # 여러 변형을 적용\n",
    "                final_image = pil_image.copy()\n",
    "                for _ in range(3):  # 세 번 변형 적용\n",
    "                    max_shift = 10  # 이동 범위 (픽셀 단위)\n",
    "                    shift_x = random.randint(-max_shift, max_shift)\n",
    "                    shift_y = random.randint(-max_shift, max_shift)\n",
    "                    transformed_image = final_image.transform(final_image.size, Image.AFFINE, (1, 0, shift_x, 0, 1, shift_y))\n",
    "\n",
    "                    # 크기 조정 (Resizing)\n",
    "                    resize_factor = random.uniform(0.5, 1.5)\n",
    "                    new_size = (int(transformed_image.size[0] * resize_factor), int(transformed_image.size[1] * resize_factor))\n",
    "                    transformed_image = transformed_image.resize(new_size)\n",
    "\n",
    "                    if self.rotational_overlay == True:\n",
    "                        # 회전 (Rotation)\n",
    "                        rotate_angle = random.randint(-30, 30)  # -30도에서 30도 사이로 회전\n",
    "                        transformed_image = transformed_image.rotate(rotate_angle)\n",
    "\n",
    "                    # 변형된 이미지를 원본 이미지에 중첩\n",
    "                    overlay_width, overlay_height = transformed_image.size\n",
    "                    max_x_offset = max(0, final_image.size[0] - overlay_width)\n",
    "                    max_y_offset = max(0, final_image.size[1] - overlay_height)\n",
    "\n",
    "                    x_offset = random.randint(0, max_x_offset)\n",
    "                    y_offset = random.randint(0, max_y_offset)\n",
    "\n",
    "                    # 중첩\n",
    "                    if transformed_image.mode == 'RGBA':\n",
    "                        final_image.paste(transformed_image, (x_offset, y_offset), transformed_image.split()[3])  # 알파 채널 처리\n",
    "                    else:\n",
    "                        final_image.paste(transformed_image, (x_offset, y_offset))\n",
    "                    # 최종 이미지를 텐서로 변환하여 저장\n",
    "\n",
    "                return transforms.ToTensor()(final_image)\n",
    "                    \n",
    "            return image  # 이미지가 공격되지 않으면 원본 이미지 그대로 반환\n",
    "\n",
    "    # 1. 결손 처리 함수 수정\n",
    "    def _corrupt_image(self, image):\n",
    "        \"\"\"이미지의 일부 픽셀을 결손 처리합니다.\"\"\"\n",
    "        if self.image_corruption == True:\n",
    "            image_np = image.numpy()  # 텐서를 NumPy 배열로 변환\n",
    "            total_pixels = image_np.size\n",
    "            num_corrupted_pixels = int(total_pixels * self.attacked_ratio)\n",
    "\n",
    "            # 랜덤으로 픽셀 선택 (이미지의 플랫(flat) 배열에서 인덱스 기준)\n",
    "            indices = random.sample(range(total_pixels), num_corrupted_pixels)\n",
    "            flat_image = image_np.flatten()\n",
    "\n",
    "            # 선택된 픽셀을 0으로 설정\n",
    "            flat_image[indices] = 0\n",
    "\n",
    "            # 이미지를 원래 형태로 복원\n",
    "            image_np = flat_image.reshape(image_np.shape)\n",
    "            return torch.tensor(image_np)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"데이터셋의 전체 길이를 반환합니다.\"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        데이터셋의 특정 샘플을 반환합니다.\n",
    "\n",
    "        Args:\n",
    "        - idx: 샘플 인덱스\n",
    "\n",
    "        Returns:\n",
    "        - (Tensor, int): 이미지 텐서와 라벨\n",
    "        \"\"\"\n",
    "        # 원본 이미지와 라벨 가져오기\n",
    "        image, original_label = self.dataset[idx]\n",
    "\n",
    "        if self.attack_order == \"label_first\":\n",
    "            # 라벨 오염 -> 이미지 겹침\n",
    "            label = self.attacked_labels[idx] if self.label_attack else original_label\n",
    "            image = self._overlay(image, idx)\n",
    "            image = self._corrupt_image(image)\n",
    "        elif self.attack_order == \"overlay_first\":\n",
    "            # 이미지 겹침 -> 라벨 오염\n",
    "            image = self._overlay(image, idx)\n",
    "            label = self.attacked_labels[idx] if self.label_attack else original_label\n",
    "            image = self._corrupt_image(image)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid attack order: {self.attack_order}. Use 'label_first' or 'overlay_first'.\")\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSiPtDKiepI3"
   },
   "source": [
    "### 실험 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3aQ0bpZHR5I"
   },
   "source": [
    "##### 1. 오염 없는 일반적 데이터 학습 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3GLSYPA4eyoh"
   },
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_res = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1V7XTDue2uB",
    "outputId": "f163034d-66a5-4936-a8a2-460cdaa4d862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss: 1.603\n",
      "Accuracy: 50.36%\n",
      "[Epoch 2] loss: 1.307\n",
      "Accuracy: 53.01%\n",
      "[Epoch 3] loss: 1.020\n",
      "Accuracy: 65.12%\n",
      "[Epoch 4] loss: 0.851\n",
      "Accuracy: 68.05%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc_res \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 24\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, device, train_loader, test_loader, epochs)\u001b[0m\n\u001b[0;32m     21\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     22\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 24\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, device, test_loader)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_res = train_and_evaluate(model_res, device, train_loader, test_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rMHgoh4HZAS"
   },
   "source": [
    "##### 2. 오염을 적용하는 데이터 학습 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGUuW6b4QhTX"
   },
   "outputs": [],
   "source": [
    "train_set_attacked = AugmentedDataset(\n",
    "    dataset=train_set,\n",
    "    perterbationset=add_set,\n",
    "    attacked_ratio=0.4,\n",
    "    overlay=True,\n",
    "    alpha=0.5,\n",
    "    label_attack=True,\n",
    "    partial_overlay=True,\n",
    "    attack_order=\"label_first\"\n",
    ")\n",
    "\n",
    "train_loader_attacked = DataLoader(dataset=train_set_attacked, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDnonxr_x5OE"
   },
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_res_1 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcScGlNrQfXP"
   },
   "outputs": [],
   "source": [
    "acc_res_1 = train_and_evaluate(model_res_1, device, train_loader_attacked, test_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLWohjWieuJV"
   },
   "source": [
    "### 최종 비교 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "eWk22manS-sn",
    "outputId": "fbc2095f-1e0d-4395-d018-b084ad37bd81"
   },
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "id": "AWQVUQLDyb_2",
    "outputId": "fe9cdfaa-6572-4bb1-c625-a878d5689932"
   },
   "outputs": [],
   "source": [
    "visualize_multiple_dataloaders([train_loader, train_loader_attacked, train_loader_attacked, train_loader_attacked, train_loader_attacked], test_loader, images_per_loader=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poison Activation Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_attacker_test = AugmentedDataset(\n",
    "    dataset=train_set,\n",
    "    perterbationset=add_set,\n",
    "    attacked_ratio=1,\n",
    "    overlay=True,\n",
    "    alpha=0.9,\n",
    "    label_attack=False,\n",
    "    label_perterbation=False,\n",
    "    partial_overlay=True,\n",
    "    image_corruption=False,\n",
    "    attack_order=\"label_first\"\n",
    ")\n",
    "\n",
    "attacker_test = DataLoader(dataset=train_set_attacker_test, batch_size=64, shuffle=True)\n",
    "\n",
    "visualize_multiple_dataloaders([train_loader, attacker_test, attacker_test, attacker_test, attacker_test], test_loader, images_per_loader=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Image Restoration Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중독데이터 복원 AI 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CIFAR-10을 학습데이터로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_10 = Autoencoder().cuda()\n",
    "unet_10 = UNet().cuda()\n",
    "\n",
    "Autotest = train_model(auto_10, train_loader, epochs=5)\n",
    "unettest = train_model(unet_10, train_loader, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 중독데이터를 학습데이터로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_attacked = Autoencoder().cuda()\n",
    "unet_attacked = UNet().cuda()\n",
    "\n",
    "Autotest_attaked = train_model(auto_attacked, train_loader_attacked, epochs=5)\n",
    "unettest_attaked = train_model(unet_attacked, train_loader_attacked, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CIFAR-100을 학습데이터로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_100 = Autoencoder().cuda()\n",
    "unet_100 = UNet().cuda()\n",
    "\n",
    "Autotest_100 = train_model(auto_100, add_loader, epochs=5)\n",
    "unettest_100 = train_model(unet_100, add_loader, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 결과 확인 함수\n",
    "def show_images(original, output):\n",
    "    # 결과 이미지를 시각화\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax[0].imshow(original.permute(1, 2, 0).cpu().detach().numpy())\n",
    "    ax[0].set_title('Original')\n",
    "    ax[1].imshow(output.permute(1, 2, 0).cpu().detach().numpy())\n",
    "    ax[1].set_title('Recovered Output')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# 학습된 모델로 테스트 이미지 확인\n",
    "unet_10.eval()\n",
    "with torch.no_grad():\n",
    "    data_iter = iter(train_loader_attacked)\n",
    "    images, _ = next(data_iter)\n",
    "    \n",
    "    outputs = unet_10(images.cuda())\n",
    "    \n",
    "    # 첫 번째 배치의 이미지 1개만 보여주기\n",
    "    show_images(images[0], outputs[0].cpu())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CIFAR-10을 학습데이터로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 학습된 모델로 테스트 이미지 확인\n",
    "auto_10.eval()\n",
    "with torch.no_grad():\n",
    "    data_iter = iter(train_loader_attacked)\n",
    "    images, _ = next(data_iter)\n",
    "\n",
    "    outputs = auto_10(images.cuda())\n",
    "    \n",
    "    # 첫 번째 배치의 이미지 1개만 보여주기\n",
    "    show_images(images[0], outputs[0].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 학습된 모델로 테스트 이미지 확인\n",
    "auto_attacked.eval()\n",
    "with torch.no_grad():\n",
    "    data_iter = iter(train_loader_attacked)\n",
    "    images, _ = next(data_iter)\n",
    "\n",
    "    outputs = unet_attacked(images.cuda())\n",
    "    \n",
    "    # 첫 번째 배치의 이미지 1개만 보여주기\n",
    "    show_images(images[0], outputs[0].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 학습된 모델로 테스트 이미지 확인\n",
    "unet_attacked.eval()\n",
    "with torch.no_grad():\n",
    "    data_iter = iter(train_loader_attacked)\n",
    "    images, _ = next(data_iter)\n",
    "\n",
    "    outputs = unet_attacked(images.cuda())\n",
    "    \n",
    "    # 첫 번째 배치의 이미지 1개만 보여주기\n",
    "    show_images(images[0], outputs[0].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 학습된 모델로 테스트 이미지 확인\n",
    "auto_100.eval()\n",
    "with torch.no_grad():\n",
    "    data_iter = iter(train_loader_attacked)\n",
    "    images, _ = next(data_iter)\n",
    "\n",
    "    outputs = auto_100(images.cuda())\n",
    "    \n",
    "    # 첫 번째 배치의 이미지 1개만 보여주기\n",
    "    show_images(images[0], outputs[0].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 학습된 모델로 테스트 이미지 확인\n",
    "unet_100.eval()\n",
    "with torch.no_grad():\n",
    "    data_iter = iter(train_loader_attacked)\n",
    "    images, _ = next(data_iter)\n",
    "\n",
    "    outputs = unet_100(images.cuda())\n",
    "    \n",
    "    # 첫 번째 배치의 이미지 1개만 보여주기\n",
    "    show_images(images[0], outputs[0].cpu())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중독된 데이터 복구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10WithModelOutputAndLabels(Dataset):\n",
    "    def __init__(self, original_data, model_outputs, labels):\n",
    "        self.original_data = original_data\n",
    "        self.model_outputs = model_outputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.original_data[idx], self.model_outputs[idx], self.labels[idx]\n",
    "\n",
    "# 이미지를 모델에 통과시키고 출력 저장하는 함수\n",
    "def process_and_save_cifar10(dataloader, model, output_filename=\"processed_cifar10_with_labels.pth\"):\n",
    "    \"\"\"\n",
    "    CIFAR-10 DataLoader에서 이미지를 처리하고, 모델의 출력과 라벨을 저장하는 함수.\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "\n",
    "    all_images = []\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # 예측 시에는 그래디언트 계산을 하지 않음\n",
    "        for images, labels in dataloader:\n",
    "            # 이미지를 GPU로 이동 (GPU가 사용 가능하면)\n",
    "            images = images.cuda() if torch.cuda.is_available() else images\n",
    "            labels = labels.cuda() if torch.cuda.is_available() else labels\n",
    "\n",
    "            # 모델을 통해 예측 결과 얻기\n",
    "            outputs = model(images)\n",
    "\n",
    "            # 결과를 리스트에 추가\n",
    "            all_images.append(images.cpu())  # CPU로 이동하여 저장\n",
    "            all_outputs.append(outputs.cpu())  # CPU로 이동하여 저장\n",
    "            all_labels.append(labels.cpu())  # CPU로 이동하여 저장\n",
    "\n",
    "    # CIFAR-10 이미지, 모델 출력, 라벨을 포함한 Dataset 생성\n",
    "    combined_dataset = CIFAR10WithModelOutputAndLabels(\n",
    "        torch.cat(all_images), torch.cat(all_outputs), torch.cat(all_labels)\n",
    "    )\n",
    "\n",
    "    # PyTorch Dataset을 저장\n",
    "    torch.save(combined_dataset, output_filename)\n",
    "    print(f\"Processed data with labels saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_10\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, auto_10, output_filename=\"auto_10.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "s_auto_10 = torch.load(\"auto_10.pth\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "images, outputs, labels = s_auto_10.original_data, s_auto_10.model_outputs, s_auto_10.labels\n",
    "\n",
    "# 예를 들어, 첫 번째 이미지와 출력 확인하기\n",
    "show_images(images[0], outputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet_10\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, unet_10, output_filename=\"unet_10.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "s_unet_10 = torch.load(\"unet_10.pth\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "images, outputs, labels = s_unet_10.original_data, s_unet_10.model_outputs, s_unet_10.labels\n",
    "\n",
    "# 예를 들어, 첫 번째 이미지와 출력 확인하기\n",
    "show_images(images[0], outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_attack\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, auto_attacked, output_filename=\"auto_attacked.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "s_auto_attacked = torch.load(\"auto_attacked.pth\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "images, outputs, labels = s_auto_attacked.original_data, s_auto_attacked.model_outputs, s_auto_attacked.labels\n",
    "\n",
    "# 예를 들어, 첫 번째 이미지와 출력 확인하기\n",
    "show_images(images[0], outputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet_attack\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, unet_attacked, output_filename=\"unet_attacked.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "s_unet_attacked = torch.load(\"unet_attacked.pth\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "images, outputs, labels = s_unet_attacked.original_data, s_unet_attacked.model_outputs, s_unet_attacked.labels\n",
    "\n",
    "# 예를 들어, 첫 번째 이미지와 출력 확인하기\n",
    "show_images(images[0], outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_100\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, auto_100, output_filename=\"auto_100.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "s_auto_100 = torch.load(\"auto_100.pth\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "images, outputs, labels = s_auto_100.original_data, s_auto_100.model_outputs, s_auto_100.labels\n",
    "\n",
    "# 예를 들어, 첫 번째 이미지와 출력 확인하기\n",
    "show_images(images[0], outputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet_100\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "    cifar10_loader = train_loader_attacked\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    process_and_save_cifar10(train_loader_attacked, unet_100, output_filename=\"unet_100.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "s_unet_100 = torch.load(\"unet_100.pth\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "images, outputs, labels = s_unet_100.original_data, s_unet_100.model_outputs, s_unet_100.labels\n",
    "\n",
    "# 예를 들어, 첫 번째 이미지와 출력 확인하기\n",
    "show_images(images[0], outputs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 복원 이미지 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_auto_10 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "model_unet_10 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "\n",
    "model_auto_attack = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "model_unet_attack = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "\n",
    "model_auto_100 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "model_unet_100 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_10 = DataLoader(dataset=s_auto_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_10 = train_and_evaluate_after(model_auto_10, device, train_loader_auto_10, test_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_10 = DataLoader(dataset=s_unet_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_10 = train_and_evaluate_after(model_unet_10, device, train_loader_unet_10, test_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_attack = DataLoader(dataset=s_auto_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_attack = train_and_evaluate_after(model_auto_attack, device, train_loader_auto_attack, test_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_attack = DataLoader(dataset=s_unet_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_attack = train_and_evaluate_after(model_unet_attack, device, train_loader_unet_attack, test_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_100 = DataLoader(dataset=s_auto_100, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_100 = train_and_evaluate_after(model_auto_100, device, train_loader_auto_100, test_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_100 = DataLoader(dataset=s_unet_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_100 = train_and_evaluate_after(model_unet_100, device, train_loader_unet_100, test_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='Poisoned')\n",
    "plt.plot(acc_auto_10, marker='x', linestyle='-', markersize=5, label='auto_10')\n",
    "plt.plot(acc_unet_10, marker='x', linestyle='-', markersize=5, label='unet_10')\n",
    "plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='auto_attack')\n",
    "plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='unet_attack')\n",
    "plt.plot(acc_auto_100, marker='x', linestyle='-', markersize=5, label='auto_100')\n",
    "plt.plot(acc_unet_100, marker='x', linestyle='-', markersize=5, label='unet_100')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "kSD6sI1ojEfo",
    "Nc6NvqDWjJjl",
    "UVF7GSn9jOB5",
    "M5haTn0vlaFa",
    "tLWohjWieuJV"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

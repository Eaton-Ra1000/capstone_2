{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqmLiUwL7O_X",
    "outputId": "13c6106c-46cf-4e00-ada6-3b422b75ea47"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4CAvsrvMES1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SPJcelp6QvVD"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhoPVyZuUmrA"
   },
   "source": [
    "===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmgm13nle1Gh"
   },
   "outputs": [],
   "source": [
    "class AugmentedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    CIFAR-10 데이터셋에 다양한 공격을 추가하는 클래스입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, perterbationset, attacked_ratio=0.2, label_attack=True, label_perterbation=True, \\\n",
    "                 overlay=True, alpha=0.5, partial_overlay=True, rotational_overlay=True, image_corruption=True, \\\n",
    "                    corruption_ratio=0.2, attack_order=\"label\", im_proc_order=\"overlay\"):\n",
    "        \"\"\" AugmentedDataset 객체를 초기화합니다. \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.perterbationset = perterbationset\n",
    "        self.attacked_ratio = attacked_ratio\n",
    "        self.label_attack = label_attack\n",
    "        self.label_perterbation = label_perterbation\n",
    "        self.overlay = overlay\n",
    "        self.alpha = alpha\n",
    "        self.partial_overlay = partial_overlay\n",
    "        self.rotational_overlay = rotational_overlay\n",
    "        self.image_corruption = image_corruption\n",
    "        self.corruption_ratio = corruption_ratio\n",
    "        self.attack_order = attack_order  # 공격 순서 설정\n",
    "        self.im_proc_order = im_proc_order\n",
    "\n",
    "        # 공격 인덱스 설정\n",
    "        self.attacked_indices = self._select_attacked_indices(self.attacked_ratio)\n",
    "\n",
    "        # Label 오염 생성 (라벨 공격이 활성화된 경우에만)\n",
    "        if self.label_attack:\n",
    "            self.attacked_labels = self._crazy_labels()\n",
    "        else:\n",
    "            self.attacked_labels = [label for _, label in self.dataset]  # 라벨 공격이 없으면 원본 라벨 사용\n",
    "\n",
    "        # Label flipping을 위한 라벨 생성 (라벨 섭동이 활성화된 경우에만)\n",
    "        if self.label_perterbation:\n",
    "            self.perbutated_labels = self._label_flipper(self.attacked_labels)\n",
    "        else:\n",
    "            self.perbutated_labels = self.attacked_labels  # 라벨 섭동이 없으면 오염된 라벨을 그대로 사용\n",
    "\n",
    "        # 변형된 이미지를 저장할 리스트 초기화\n",
    "        self.transformed_images = [None] * len(self.dataset)\n",
    "\n",
    "        # 이미지 오염 및 이미지 겹침 초기화 (이미지를 한 번만 오염 처리)\n",
    "        self.processed_images = [None] * len(self.dataset)\n",
    "        for idx in range(len(self.dataset)):\n",
    "            image, _ = self.dataset[idx]\n",
    "            image = self.__image_process__(image, idx)  # 초기화 시 한 번만 이미지 처리\n",
    "            self.processed_images[idx] = image  # 처리된 이미지 저장\n",
    "\n",
    "    def _select_attacked_indices(self, ratio):\n",
    "        \"\"\"공격 대상 샘플의 인덱스를 선택합니다.\"\"\"\n",
    "        num_attack_samples = int(ratio * len(self.dataset))\n",
    "        return random.sample(range(len(self.dataset)), num_attack_samples)\n",
    "\n",
    "    def _crazy_labels(self):\n",
    "        \"\"\"Label 오염된 라벨 리스트를 생성합니다.\"\"\"\n",
    "        attacked_labels = []\n",
    "        for idx in range(len(self.dataset)):\n",
    "            _, original_label = self.dataset[idx]\n",
    "            if idx in self.attacked_indices:\n",
    "                # 원래 라벨과 다른 무작위 라벨 생성\n",
    "                attacked_label = original_label\n",
    "                while attacked_label == original_label:\n",
    "                    attacked_label = random.randint(0, 9)\n",
    "                attacked_labels.append(attacked_label)\n",
    "            else:\n",
    "                attacked_labels.append(original_label)\n",
    "        return attacked_labels\n",
    "\n",
    "    def _label_flipper(self, target):\n",
    "        \"\"\"\n",
    "        CIFAR-10 데이터셋의 일부 샘플에 Label-Flipping 오염을 가하는 함수입니다.\n",
    "        \"\"\"\n",
    "        perbutated_labels = []\n",
    "\n",
    "        for idx in range(len(target)):\n",
    "            label = target[idx]\n",
    "\n",
    "            if idx in self.attacked_indices:\n",
    "                # 라벨 복사 후 공격 수행\n",
    "                original_label = label\n",
    "\n",
    "                if original_label == 1:\n",
    "                    label = 9\n",
    "                elif original_label == 9:\n",
    "                    label = 1\n",
    "                elif original_label == 5:\n",
    "                    label = 3\n",
    "                elif original_label == 3:\n",
    "                    label = 5\n",
    "                elif original_label == 7:\n",
    "                    label = 4\n",
    "                elif original_label == 4:\n",
    "                    label = 7\n",
    "                elif original_label == 2:\n",
    "                    label = 6\n",
    "                elif original_label == 6:\n",
    "                    label = 2\n",
    "                elif original_label == 0:\n",
    "                    label = 8\n",
    "                elif original_label == 8:\n",
    "                    label = 0\n",
    "\n",
    "            perbutated_labels.append(label)\n",
    "\n",
    "        return perbutated_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"데이터셋의 전체 길이를 반환합니다.\"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __image_process__(self, image, idx):\n",
    "        \"\"\"이미지 처리 순서 함수\"\"\"\n",
    "        if self.im_proc_order == \"overlay\":\n",
    "            image = self._overlay(image, idx) if self.overlay == True else image\n",
    "            image = self._corrupt_image(image, idx) if self.image_corruption == True else image\n",
    "        elif self.im_proc_order == \"corrupt\":\n",
    "            image = self._corrupt_image(image, idx) if self.image_corruption == True else image\n",
    "            image = self._overlay(image, idx) if self.overlay == True else image\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid im_proc_order: {self.im_proc_order}. Use 'overlay' or 'corrupt'.\")\n",
    "\n",
    "        return image\n",
    "\n",
    "    def _overlay(self, image, idx):\n",
    "        \"\"\"특정 이미지에 이미지 겹침 공격을 적용합니다.\"\"\"\n",
    "        if idx in self.attacked_indices:\n",
    "            if self.partial_overlay:\n",
    "                # 텐서를 PIL 이미지로 변환\n",
    "                pil_image = transforms.ToPILImage()(image)\n",
    "\n",
    "                # 두 개의 이미지를 랜덤으로 선택하여 중첩\n",
    "                rand_idx_1 = random.randint(0, len(self.dataset) - 1)\n",
    "                rand_idx_2 = random.randint(0, len(self.dataset) - 1)\n",
    "\n",
    "                overlay_image_1, _ = self.dataset[rand_idx_1]\n",
    "                overlay_image_2, _ = self.dataset[rand_idx_2]\n",
    "\n",
    "                # 첫 번째 이미지를 중첩\n",
    "                overlay_h_1, overlay_w_1 = overlay_image_1.shape[1], overlay_image_1.shape[2]\n",
    "                scale_factor_1 = random.uniform(0.5, 1.0)\n",
    "                new_h_1 = int(overlay_h_1 * scale_factor_1)\n",
    "                new_w_1 = int(overlay_w_1 * scale_factor_1)\n",
    "\n",
    "                overlay_image_1_pil = transforms.ToPILImage()(overlay_image_1)\n",
    "                overlay_image_1_resized = overlay_image_1_pil.resize((new_w_1, new_h_1))\n",
    "\n",
    "                x1 = random.randint(0, pil_image.size[0] - new_w_1)\n",
    "                y1 = random.randint(0, pil_image.size[1] - new_h_1)\n",
    "                pil_image.paste(overlay_image_1_resized, (x1, y1))\n",
    "\n",
    "                # 두 번째 이미지를 중첩\n",
    "                overlay_h_2, overlay_w_2 = overlay_image_2.shape[1], overlay_image_2.shape[2]\n",
    "                scale_factor_2 = random.uniform(0.5, 1.0)\n",
    "                new_h_2 = int(overlay_h_2 * scale_factor_2)\n",
    "                new_w_2 = int(overlay_w_2 * scale_factor_2)\n",
    "\n",
    "                overlay_image_2_pil = transforms.ToPILImage()(overlay_image_2)\n",
    "                overlay_image_2_resized = overlay_image_2_pil.resize((new_w_2, new_h_2))\n",
    "\n",
    "                x2 = random.randint(0, pil_image.size[0] - new_w_2)\n",
    "                y2 = random.randint(0, pil_image.size[1] - new_h_2)\n",
    "                pil_image.paste(overlay_image_2_resized, (x2, y2))\n",
    "\n",
    "                # 최종 이미지를 텐서로 변환하여 저장\n",
    "                final_image = transforms.ToTensor()(pil_image)\n",
    "                return final_image\n",
    "        \n",
    "        return image  # 이미지가 공격되지 않으면 원본 이미지 그대로 반환\n",
    "\n",
    "    def _corrupt_image(self, image, idx):\n",
    "        \"\"\"이미지의 일부 픽셀을 결손 처리합니다.\"\"\"\n",
    "        if self.image_corruption:\n",
    "            if idx in self.attacked_indices:\n",
    "                image_np = image.numpy()  # 텐서를 NumPy 배열로 변환\n",
    "                total_pixels = image_np.size\n",
    "                num_corrupted_pixels = int(total_pixels * self.corruption_ratio)\n",
    "\n",
    "                # 랜덤으로 픽셀 선택 (이미지의 플랫(flat) 배열에서 인덱스 기준)\n",
    "                indices = random.sample(range(total_pixels), num_corrupted_pixels)\n",
    "                flat_image = image_np.flatten()\n",
    "\n",
    "                # 선택된 픽셀을 0으로 설정\n",
    "                flat_image[indices] = 0\n",
    "\n",
    "                # 이미지를 원래 형태로 복원\n",
    "                image_np = flat_image.reshape(image_np.shape)\n",
    "                return torch.tensor(image_np)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        데이터셋의 특정 샘플을 반환합니다.\n",
    "        \"\"\"\n",
    "        # 원본 이미지와 라벨 가져오기\n",
    "        original_images, original_label = self.dataset[idx]\n",
    "\n",
    "        # 라벨 오염 및 이미지 오염 처리된 데이터 반환\n",
    "        image = self.processed_images[idx]\n",
    "        label = self.perbutated_labels[idx]\n",
    "\n",
    "        return original_images, original_label, image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYQyDuPoced9",
    "outputId": "7f130753-2eff-45cd-e254-366ea2f5e909"
   },
   "outputs": [],
   "source": [
    "data = torch.load('poisoned.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JL_XZ13qf9ZM",
    "outputId": "83b8105e-88be-4c88-8194-8eadf151cbd2"
   },
   "outputs": [],
   "source": [
    "# DataLoader로 모든 데이터를 한 번에 불러오기\n",
    "data_loader = DataLoader(data, batch_size=len(data))  # 데이터 전체를 하나의 배치로 가져옴\n",
    "\n",
    "for batch in data_loader:\n",
    "    original_images, original_labels, poisoned_images, poisoned_labels = batch\n",
    "    break  # 모든 데이터를 한 번에 가져왔으므로 반복문 종료\n",
    "\n",
    "# 확인\n",
    "print(original_images.shape)\n",
    "print(original_labels.shape)\n",
    "print(poisoned_images.shape)\n",
    "print(poisoned_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDseyC-JmPgR"
   },
   "outputs": [],
   "source": [
    "def nl_means_restore(image_tensor, h=10, templateWindowSize=7, searchWindowSize=21):\n",
    "    \"\"\"\n",
    "    단일 이미지를 NL-Means 필터로 복원.\n",
    "    Args:\n",
    "        image_tensor (torch.Tensor): 입력 이미지 텐서, 크기 (3, H, W)\n",
    "        h (int): 필터 강도\n",
    "        templateWindowSize (int): 템플릿 윈도우 크기\n",
    "        searchWindowSize (int): 검색 윈도우 크기\n",
    "    Returns:\n",
    "        torch.Tensor: 복원된 이미지 텐서, 크기 (3, H, W)\n",
    "    \"\"\"\n",
    "    # (3, H, W) -> (H, W, 3)로 변환\n",
    "    image_np = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "    image_np = (image_np * 255).astype('uint8')  # 0-1 스케일링된 경우 uint8로 변환\n",
    "\n",
    "    # NL-Means 복원 (컬러 이미지)\n",
    "    restored_np = cv2.fastNlMeansDenoisingColored(\n",
    "        image_np, h=h, hColor=h, templateWindowSize=templateWindowSize, searchWindowSize=searchWindowSize\n",
    "    )\n",
    "\n",
    "    # (H, W, 3) -> (3, H, W)로 다시 변환\n",
    "    restored_tensor = torch.tensor(restored_np).permute(2, 0, 1).float() / 255.0  # 다시 0-1로 정규화\n",
    "    return restored_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WuAPJGBum5Ux"
   },
   "outputs": [],
   "source": [
    "def apply_nl_means_to_dataset(images, batch_size=1000, h=10, templateWindowSize=7, searchWindowSize=21):\n",
    "    \"\"\"\n",
    "    전체 데이터셋에 NL-Means 필터 적용.\n",
    "    Args:\n",
    "        images (torch.Tensor): 이미지 데이터셋, 크기 (N, 3, H, W)\n",
    "        batch_size (int): 처리할 배치 크기\n",
    "        h (int): 필터 강도\n",
    "        templateWindowSize (int): 템플릿 윈도우 크기\n",
    "        searchWindowSize (int): 검색 윈도우 크기\n",
    "    Returns:\n",
    "        torch.Tensor: 복원된 이미지 데이터셋, 크기 (N, 3, H, W)\n",
    "    \"\"\"\n",
    "    restored_images = []\n",
    "\n",
    "    # 배치 단위로 처리 (메모리 관리)\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch = images[i:i + batch_size]\n",
    "        restored_batch = [nl_means_restore(image, h, templateWindowSize, searchWindowSize) for image in batch]\n",
    "        restored_images.extend(restored_batch)\n",
    "\n",
    "    return torch.stack(restored_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJ8t25bpm7kD",
    "outputId": "97951791-9ccf-45b8-e018-1bdf98fcec04"
   },
   "outputs": [],
   "source": [
    "# 가상의 데이터셋 생성 (torch.Size([50000, 3, 32, 32]))\n",
    "images = poisoned_images\n",
    "\n",
    "# NL-Means 복원 수행\n",
    "restored_images = apply_nl_means_to_dataset(images, batch_size=1000, h=10)\n",
    "\n",
    "print(f\"Restored Images Shape: {restored_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fhuajt9xvQFi"
   },
   "outputs": [],
   "source": [
    "# 시각화 함수\n",
    "def visualize_image_comparisons(image_sets, num_images=5, random_select=True):\n",
    "    \"\"\"\n",
    "    여러 종류의 이미지 텐서에서 동일한 인덱스의 이미지를 선택하여 시각화.\n",
    "\n",
    "    Args:\n",
    "        image_sets (list of torch.Tensor): 이미지 텐서 목록, 각각 크기 [N, H, W, C]\n",
    "        num_images (int): 표시할 이미지 개수\n",
    "        random_select (bool): True이면 랜덤 인덱스 선택, False이면 순서대로 선택\n",
    "    \"\"\"\n",
    "    num_sets = len(image_sets)  # 열의 개수\n",
    "    num_samples = len(image_sets[0])  # 각 텐서의 이미지 개수\n",
    "\n",
    "    # 선택할 인덱스\n",
    "    if random_select:\n",
    "        indices = random.sample(range(num_samples), num_images)\n",
    "    else:\n",
    "        indices = list(range(num_images))\n",
    "\n",
    "    # 시각화\n",
    "    plt.figure(figsize=(num_sets * 3, num_images * 2))  # (가로 크기, 세로 크기)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        for j, image_set in enumerate(image_sets):\n",
    "            plt.subplot(num_images, num_sets, i * num_sets + j + 1)\n",
    "            plt.axis('off')\n",
    "            # (C, H, W) to (H, W, C) using permute\n",
    "            image_to_show = image_set[idx].permute(1, 2, 0).numpy()\n",
    "            plt.imshow(image_to_show)  # 이미지 표시\n",
    "            if i == 0:  # 첫 번째 행에만 제목 추가\n",
    "                plt.title(f\"Set {j + 1}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnCY6BIrpZty"
   },
   "outputs": [],
   "source": [
    "restoring_val = torch.abs(restored_images - original_images)  # 복원효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQLWWgxNqaj_"
   },
   "outputs": [],
   "source": [
    "#오염 추출 시도 - (5번-3번)\n",
    "attacked_characteristic = torch.abs(restored_images - poisoned_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "thLH9HrRzPLH",
    "outputId": "2d19c196-d92f-4a6e-85ff-cc0c647c5ab5"
   },
   "outputs": [],
   "source": [
    "# 함수 호출: 동일 인덱스의 이미지를 5개씩 랜덤으로 비교\n",
    "images_sets = [original_images, poisoned_images, restored_images, restoring_val, attacked_characteristic]\n",
    "visualize_image_comparisons(images_sets, num_images=5, random_select=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUlXn-mo-Oaa"
   },
   "source": [
    "#오염 특성 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Me_nCWE4-RIt",
    "outputId": "ef95cbb1-d6fa-4ee8-c93e-20eb4241531f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

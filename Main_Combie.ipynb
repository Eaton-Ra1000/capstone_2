{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgnERK0iT7U_"
   },
   "source": [
    "### 함수 저장소\n",
    "\n",
    "1. 학습 데이터셋 비교 가시화\n",
    "\n",
    "visualize_multiple_dataloaders([test_loader], test_loader, images_per_loader=5)\n",
    "\n",
    "2. 실험 진행용 학습모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Master Switch Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Retrain Option\n",
    "#모델/데이터 전체 리셋\n",
    "Data_Reset = False\n",
    "#학습된 모델 없등면 자동으로 학습\n",
    "Auto_Init = True\n",
    "defualt_epoch = 5\n",
    "#Model Save Path\n",
    "default_path = \"default_path_less_corrupt_Maintanence\"\n",
    "#로그 기록 여부\n",
    "log_save = True\n",
    "## Switch Baord based on stage\n",
    "poision_sys_reset = False\n",
    "restore_sys_reset = False\n",
    "reclass_sys_reset = True\n",
    "multiplier_sys_reset = False\n",
    "##Muliplier_sys_reset by Type\n",
    "M_reset_auto_10 =False\n",
    "M_reset_unet_10 =False\n",
    "M_reset_auto_attacked =False\n",
    "M_reset_unet_attacked =False\n",
    "M_reset_auto_100 =False\n",
    "M_reset_unet_100 = False\n",
    "# CUDA 이용 GPU 번호 입력 (Default : 0)\n",
    "GPU_NUM = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSD6sI1ojEfo"
   },
   "source": [
    "### 1. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0k8rocQiudv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "#t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#train function\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLjVNkuKCpcG",
    "outputId": "5ed1d8c3-224d-47b4-cf51-c229da4eb7b8"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    if GPU_NUM > (torch.cuda.device_count() - 1):\n",
    "        GPU_NUM = torch.cuda.device_count() - 1\n",
    "    device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.set_device(device) # change allocation of current GPU\n",
    "    print('Current cuda device:', torch.cuda.current_device())\n",
    "    print('Count of using GPUs:', torch.cuda.device_count())\n",
    "else:\n",
    "    device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Automated Git Ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gitignore(directory = default_path, gitignore_path=\".gitignore\"):\n",
    "\n",
    "    # .gitignore 파일이 존재하는지 확인\n",
    "    if not os.path.exists(gitignore_path):\n",
    "        print(f\"{gitignore_path} 파일이 존재하지 않습니다. 새로 생성합니다.\")\n",
    "        with open(gitignore_path, 'w') as f:\n",
    "            f.write(\"\")  # 빈 .gitignore 파일 생성\n",
    "    \n",
    "    # .gitignore 파일을 읽기\n",
    "    with open(gitignore_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # 이미 디렉토리가 .gitignore에 있는지 확인\n",
    "    ignore_line = f\"{directory}/\\n\"\n",
    "    if ignore_line not in lines:\n",
    "        # 디렉토리가 없으면 추가\n",
    "        with open(gitignore_path, 'a') as f:\n",
    "            f.write(ignore_line)\n",
    "        print(f\"{directory} 디렉토리를 .gitignore에 추가했습니다.\")\n",
    "    else:\n",
    "        print(f\"{directory} 디렉토리가 이미 .gitignore에 존재합니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nc6NvqDWjJjl"
   },
   "source": [
    "### 2. 데이터셋 정의 - 비오염"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n93dhuI8kEqb"
   },
   "outputs": [],
   "source": [
    "# Data loading and transformations\n",
    "transform = transforms.Compose([\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.RandomCrop(32, padding=4),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1YfR7U4CCn_",
    "outputId": "b2ca1462-5373-4ef9-ef4c-b8be73959186"
   },
   "outputs": [],
   "source": [
    "# Use PyTorch's torchvision.transforms.ToTenesor() to convert the dataset to tensor format\n",
    "train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "add_set = CIFAR100(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iv1xifZj_B5Q"
   },
   "outputs": [],
   "source": [
    "# Use PyTorch's DataLoader to divide the dataset into mini-batches and load the data\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=False)\n",
    "add_loader = DataLoader(dataset=add_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYGOwI2lrw3l"
   },
   "outputs": [],
   "source": [
    "def visualize_multiple_dataloaders(dataloaders, trainloader, images_per_loader=5):\n",
    "    num_loaders = len(dataloaders)\n",
    "    classes = trainloader.dataset.classes\n",
    "\n",
    "    # 플롯 크기 설정\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    for i, loader in enumerate(dataloaders):\n",
    "        # 각 DataLoader에서 배치 하나 가져오기\n",
    "        batch = next(iter(loader))\n",
    "        if len(batch) == 2:\n",
    "            images, labels = batch\n",
    "        elif len(batch) == 4:\\\n",
    "            _ , _, images, labels = batch\n",
    "        images = torch.clamp(images, 0, 1)  # 이미지를 0과 1 사이로 클리핑하여 표시 문제 방지\n",
    "\n",
    "        # 각 DataLoader에서 선택한 이미지 수만큼 시각화\n",
    "        for j in range(images_per_loader):\n",
    "            idx = i * images_per_loader + j\n",
    "            plt.subplot(num_loaders, images_per_loader, idx + 1)\n",
    "            plt.imshow(images[j].permute(1, 2, 0))  # 이미지 차원 변경: (C, H, W) -> (H, W, C)\n",
    "            plt.title(classes[labels[j].item()])\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVF7GSn9jOB5"
   },
   "source": [
    "### 3. 신경망 코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxUFFR4Akpau"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Autoencoder 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder 부분\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),   # 32x32 -> 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # 16x16 -> 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1), # 8x8 -> 4x4\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128)  # latent space (압축된 표현)\n",
    "        )\n",
    "        \n",
    "        # Decoder 부분\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256 * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (256, 4, 4)),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1), # 4x4 -> 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),   # 8x8 -> 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),     # 16x16 -> 32x32\n",
    "            nn.Tanh()  # 0~1 범위로 출력\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. U-Net 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # 인코더 (Contracting Path)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # 32x32 -> 16x16\n",
    "        )\n",
    "        \n",
    "        self.encoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # 16x16 -> 8x8\n",
    "        )\n",
    "        \n",
    "        self.encoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # 8x8 -> 4x4\n",
    "        )\n",
    "\n",
    "        # 병목층 (Bottleneck)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 디코더 (Expanding Path)\n",
    "        self.decoder_1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')  # 4x4 -> 8x8\n",
    "        )\n",
    "        \n",
    "        self.decoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')  # 8x8 -> 16x16\n",
    "        )\n",
    "        \n",
    "        self.decoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')  # 16x16 -> 32x32\n",
    "        )\n",
    "        \n",
    "        # 최종 출력 레이어\n",
    "        self.final_conv = nn.Conv2d(64, 3, kernel_size=3, padding=1)  # 출력 채널 3 (RGB 이미지)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 인코더\n",
    "        enc1 = self.encoder(x)\n",
    "        enc2 = self.encoder_2(enc1)\n",
    "        enc3 = self.encoder_3(enc2)\n",
    "        \n",
    "        # 병목층\n",
    "        bottleneck = self.bottleneck(enc3)\n",
    "        \n",
    "        # 디코더\n",
    "        dec1 = self.decoder_1(bottleneck)\n",
    "        dec2 = self.decoder_2(dec1)\n",
    "        dec3 = self.decoder_3(dec2)\n",
    "        \n",
    "        # 최종 출력\n",
    "        out = self.final_conv(dec3)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSNE_Model(torch.nn.Module):\n",
    "    def __init__(self, n_components=2, perplexity=30.0, n_iter=1000):\n",
    "        super(TSNE_Model, self).__init__()\n",
    "        self.n_components = n_components\n",
    "        self.perplexity = perplexity\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X: (N, D) tensor, where N is the number of data points and D is the dimension of each data point\n",
    "        \"\"\"\n",
    "        X = X.detach().cpu().numpy()  # PyTorch tensor -> NumPy array\n",
    "        tsne = TSNE(n_components=self.n_components, perplexity=self.perplexity, n_iter=self.n_iter)\n",
    "        tsne_results = tsne.fit_transform(X)\n",
    "        return torch.tensor(tsne_results, dtype=torch.float32).to(X.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 NLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLM_Model(torch.nn.Module):\n",
    "    def __init__(self, patch_size=3, search_window=7, h=0.1):\n",
    "        super(NLM_Model, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.search_window = search_window\n",
    "        self.h = h\n",
    "\n",
    "    def forward(self, noisy_image):\n",
    "        \"\"\"\n",
    "        noisy_image: (C, H, W) 텐서, C는 채널, H와 W는 높이와 너비\n",
    "        \"\"\"\n",
    "        C, H, W = noisy_image.shape\n",
    "        denoised_image = torch.zeros_like(noisy_image)\n",
    "        \n",
    "        # 패치 크기와 검색 창 크기 설정\n",
    "        half_patch = self.patch_size // 2\n",
    "        half_window = self.search_window // 2\n",
    "        \n",
    "        # Non-Local Means 알고리즘 적용\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                # 현재 픽셀과 주변 패치를 비교\n",
    "                patch_center = noisy_image[:, i, j]\n",
    "                weight_sum = 0\n",
    "                weighted_sum = torch.zeros(C)\n",
    "                \n",
    "                # 검색 창 내에서 유사한 패치 찾아 가중 평균 계산\n",
    "                for x in range(max(0, i - half_window), min(H, i + half_window + 1)):\n",
    "                    for y in range(max(0, j - half_window), min(W, j + half_window + 1)):\n",
    "                        # 기준 패치와 주변 패치\n",
    "                        patch_1 = noisy_image[:, max(0, i-half_patch):min(H, i+half_patch+1), max(0, j-half_patch):min(W, j+half_patch+1)]\n",
    "                        patch_2 = noisy_image[:, max(0, x-half_patch):min(H, x+half_patch+1), max(0, y-half_patch):min(W, y+half_patch+1)]\n",
    "                        \n",
    "                        # 패치 간의 차이 계산\n",
    "                        dist = torch.sum((patch_1 - patch_2) ** 2)\n",
    "                        weight = torch.exp(-dist / (self.h ** 2))\n",
    "                        \n",
    "                        # 가중 평균\n",
    "                        weighted_sum += weight * noisy_image[:, x, y]\n",
    "                        weight_sum += weight\n",
    "                \n",
    "                # 현재 픽셀의 복원 값 설정\n",
    "                denoised_image[:, i, j] = weighted_sum / weight_sum if weight_sum != 0 else patch_center\n",
    "        \n",
    "        return denoised_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.deconv1(x))\n",
    "        x = self.relu(self.deconv2(x))\n",
    "        x = self.tanh(self.deconv3(x))\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
    "        self.fc = nn.Linear(256 * 4 * 4, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.LeakyReLU(self.conv1(x))\n",
    "        x = self.LeakyReLU(self.conv2(x))\n",
    "        x = self.LeakyReLU(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.sigmoid(self.fc(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7  DNCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5haTn0vlaFa"
   },
   "source": [
    "### 4. 신경망 학습과 테스트 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic Train and evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJhbIRtSqUIN"
   },
   "outputs": [],
   "source": [
    "# Train and evaluate function\n",
    "def train_and_evaluate(model, train_loader, test_loader, device = device, epochs=defualt_epoch, \\\n",
    "                       Data_Reset = Data_Reset, net_reset = False, folder_path = default_path, \\\n",
    "                       net_name = \"defual_net.pt\", log_save = log_save, log_name = \"default_log\"):\n",
    "  \n",
    "  if os.path.exists(folder_path)== False:\n",
    "    print(\"디렉토리 없음\")\n",
    "    if net_reset == False and Data_Reset == False and Auto_Init == False:\n",
    "      return\n",
    "  \n",
    "    os.mkdir(folder_path)\n",
    "    print(\"디렉토리를 만들었습니다 : \", folder_path)\n",
    "    gitignore(directory = folder_path)\n",
    "  \n",
    "  os.chdir(folder_path)\n",
    "\n",
    "  if os.path.exists(net_name) == False and Auto_Init == False:\n",
    "      print(\"학습데이터 없음\")\n",
    "      os.chdir(\"../\")\n",
    "      return\n",
    "\n",
    "  if net_reset == True or Data_Reset == True or (os.path.exists(net_name) == False and Auto_Init == True):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # DataLoader에서 데이터 항목 개수 확인\n",
    "    for batch in train_loader:\n",
    "        num_items = len(batch)  # 배치에서 항목 개수 확인\n",
    "        print(\"Number of Data Type:\", num_items)\n",
    "        break\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      running_loss = 0.0\n",
    "\n",
    "      if num_items == 2:\n",
    "        for data in train_loader:\n",
    "            original_images, original_labels = data\n",
    "            original_images, original_labels = original_images.to(device), original_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(original_images)\n",
    "            loss = criterion(outputs, original_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "      \n",
    "      elif num_items == 4:\n",
    "        for data in train_loader:\n",
    "            _, _, poisoned_images, poisoned_labels = data\n",
    "            poisoned_images, poisoned_labels = poisoned_images.to(device), poisoned_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(poisoned_images)\n",
    "\n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, poisoned_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "      elif num_items == 5:\n",
    "        for data in train_loader:\n",
    "            _, _, _, poisoned_labels, restored_images = data\n",
    "            restored_images, poisoned_labels = restored_images.to(device), poisoned_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(restored_images)\n",
    "\n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, poisoned_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "      elif num_items == 6:\n",
    "        for data in train_loader:\n",
    "            _, _, _, poisoned_labels, _,  restored_images = data\n",
    "            restored_images, poisoned_labels = restored_images.to(device), poisoned_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(restored_images)\n",
    "\n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, poisoned_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "      else :\n",
    "          print(\"dataset error\")\n",
    "          os.chdir(\"../\")\n",
    "          return \n",
    "        \n",
    "      print(f'[Epoch {epoch + 1}] loss: {running_loss / len(train_loader):.3f}')\n",
    "\n",
    "      accuracy = evaluate(model, device, test_loader)\n",
    "      accuracies.append(accuracy)\n",
    "      print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    torch.save(model, net_name)\n",
    "    print(\"모델을 저장하였습니다 : \", net_name)\n",
    "    \n",
    "    if log_save == True or Data_Reset == True or (os.path.exists(net_name) == False and Auto_Init == True):\n",
    "      np.save(log_name, accuracies)\n",
    "      print(\"로그를 저장하였습니다 : \", log_name, \".npy\")\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "      \n",
    "  \n",
    "  else:  \n",
    "    if os.path.exists(log_name+\".npy\")== False:\n",
    "      print(\"accuracies 없음 (모델 로드가능)\")\n",
    "      accuracies = []\n",
    "\n",
    "    else:  \n",
    "      accuracies_np = np.load(log_name+\".npy\")\n",
    "      accuracies = accuracies_np.tolist()\n",
    "      print(\"accuracies 로드됨\")\n",
    "  print(os.getcwd())\n",
    "  \n",
    "  os.chdir(\"../\")\n",
    "  return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJD8q_BHlfkv"
   },
   "outputs": [],
   "source": [
    "# Evaluate function\n",
    "def evaluate(model, device, test_loader, ex_load = False, load_dict = \"./default_net.pt\"):\n",
    "  if ex_load == True :\n",
    "    model = torch.load(load_dict)\n",
    "  model.eval()\n",
    "  total_correct = 0\n",
    "  with torch.no_grad():\n",
    "     for data, target in test_loader:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      output = model(data)\n",
    "      _, preds = torch.max(output, 1)\n",
    "      total_correct += (preds == target).sum().item()\n",
    "\n",
    "  accuracy = 100 * total_correct / len(test_loader.dataset)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Image Restoration Neural Network Train Function\n",
    "##### Autoencoder/ Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def train_model(model, trainloader, device = device,  epochs=defualt_epoch, \\\n",
    "                       Data_Reset = Data_Reset, net_reset = False, folder_path = default_path, \\\n",
    "                       net_name = \"defual_net.pt\", log_save = log_save, log_name = \"default_log\"):\n",
    "    \n",
    "    if os.path.exists(folder_path)== False:\n",
    "        print(\"디렉토리 없음\")\n",
    "        if net_reset == False and Data_Reset == False and Auto_Init == False:\n",
    "            return\n",
    "        \n",
    "        os.mkdir(folder_path)\n",
    "        print(\"디렉토리를 만들었습니다 : \", folder_path)\n",
    "        gitignore(directory = folder_path)\n",
    "\n",
    "    os.chdir(folder_path)\n",
    "\n",
    "    if os.path.exists(net_name)== False and Auto_Init == False:\n",
    "            print(\"학습데이터 없음\")\n",
    "            os.chdir(\"../\")\n",
    "            return\n",
    "    \n",
    "    # DataLoader에서 데이터 항목 개수 확인\n",
    "    for batch in trainloader:\n",
    "        num_items = len(batch)  # 배치에서 항목 개수 확인\n",
    "        print(\"Number of Data Type:\", num_items)\n",
    "        break\n",
    "    \n",
    "    if net_reset == True or Data_Reset == True or (os.path.exists(net_name) == False and Auto_Init == True):\n",
    "    \n",
    "        model.train()\n",
    "        loss = []\n",
    "\n",
    "        criterion = nn.MSELoss()  # 평균 제곱 오차 (복원된 이미지와 원본 이미지 간의 차이)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for data in trainloader:\n",
    "                if num_items == 2 :\n",
    "                    inputs, _ = data\n",
    "                    inputs = inputs.to(device)\n",
    "\n",
    "                    # 손상된 이미지 생성 (노이즈 추가)\n",
    "                    poisoned = inputs + 0.1 * torch.randn_like(inputs)\n",
    "                    poisoned = torch.clip(poisoned, 0., 1.)  # 값이 0~1 사이로 유지되도록 조정\n",
    "\n",
    "                elif num_items == 4 :\n",
    "                    inputs, _, poisoned, _ = data  # 레이블은 필요 없음\n",
    "                    inputs = inputs.to(device)\n",
    "                    poisoned = poisoned.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 모델에 손상된 이미지 입력\n",
    "                outputs = model(poisoned)\n",
    "                \n",
    "                # 손실 계산\n",
    "                loss = criterion(outputs, inputs)  # 원본 이미지와 복원된 이미지 간의 차이\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader)}')\n",
    "        \n",
    "\n",
    "        torch.save(model, net_name)\n",
    "        print(\"모델을 저장하였습니다 : \", net_name)\n",
    "        \n",
    "        if log_save == True or Data_Reset == True or (os.path.exists(net_name) == False and Auto_Init == True):\n",
    "            loss = loss.cpu()\n",
    "            np.save(log_name, loss.detach().numpy())\n",
    "            print(\"로그를 저장하였습니다 : \", log_name, \".npy\")\n",
    "        \n",
    "        print(os.getcwd())    \n",
    "        os.chdir(\"../\")\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return            \n",
    "        \n",
    "    else:      \n",
    "        if os.path.exists(log_name+\".npy\")== False:\n",
    "            print(\"accuracies 없음 (모델 로드 가능)\")\n",
    "            loss = []\n",
    "\n",
    "        else:  \n",
    "            loss = torch.from_numpy(np.load(log_name+\".npy\"))\n",
    "            print(\"loss 로드됨\")\n",
    "        \n",
    "        print(os.getcwd())\n",
    "        os.chdir(\"../\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def GAN_trainer(model_generator, model_discriminator, trainloader, device = device,  epochs=defualt_epoch, \\\n",
    "                       Data_Reset = Data_Reset, net_reset = False, folder_path = default_path, \\\n",
    "                       net_g_name = \"defualt_net_g.pt\", net_d_name = \"defualt_net_d.pt\"):\n",
    "    \n",
    "    if os.path.exists(folder_path)== False:\n",
    "        print(\"디렉토리 없음\")\n",
    "        if net_reset == False and Data_Reset == False and Auto_Init == False:\n",
    "            return\n",
    "        \n",
    "        os.mkdir(folder_path)\n",
    "        print(\"디렉토리를 만들었습니다 : \", folder_path)\n",
    "        gitignore(directory = folder_path)\n",
    "\n",
    "    os.chdir(folder_path)\n",
    "\n",
    "    if (not(os.path.exists(net_g_name)== True and os.path.exists(net_d_name)== True)) and Auto_Init == False:\n",
    "            print(\"학습데이터 없음\")\n",
    "            os.chdir(\"../\")\n",
    "            return\n",
    "    \n",
    "    # DataLoader에서 데이터 항목 개수 확인\n",
    "    for batch in trainloader:\n",
    "        num_items = len(batch)  # 배치에서 항목 개수 확인\n",
    "        print(\"Number of Data Type:\", num_items)\n",
    "        break\n",
    "    \n",
    "    if net_reset == True or Data_Reset == True or ((not(os.path.exists(net_g_name)== True and os.path.exists(net_d_name)== True)) and Auto_Init == True):\n",
    "        \n",
    "        # 손실 함수와 옵티마이저 정의\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer_g = optim.Adam(model_generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        optimizer_d = optim.Adam(model_discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for data in trainloader:\n",
    "                if num_items == 2 :\n",
    "                    inputs, _ = data\n",
    "                    inputs = inputs.to(device)\n",
    "\n",
    "                    # 손상된 이미지 생성 (노이즈 추가)\n",
    "                    poisoned = inputs + 0.1 * torch.randn_like(inputs)\n",
    "                    poisoned = torch.clip(poisoned, 0., 1.)  # 값이 0~1 사이로 유지되도록 조정\n",
    "\n",
    "                elif num_items == 4 :\n",
    "                    inputs, _, poisoned, _ = data  # 레이블은 필요 없음\n",
    "                    inputs = inputs.to(device)\n",
    "                    poisoned = poisoned.to(device)\n",
    "\n",
    "                # 실제 레이블은 1, 가짜 레이블은 0\n",
    "                real_labels = torch.ones(inputs.size(0), 1).cuda()\n",
    "                fake_labels = torch.zeros(inputs.size(0), 1).cuda()\n",
    "\n",
    "                # -----------------\n",
    "                # Discriminator 훈련\n",
    "                # -----------------\n",
    "                optimizer_d.zero_grad()\n",
    "\n",
    "                # 실제 이미지에 대해 Discriminator 훈련\n",
    "                real_outputs = model_discriminator(inputs)\n",
    "                d_loss_real = criterion(real_outputs, real_labels)\n",
    "\n",
    "                # 가짜 이미지에 대해 Discriminator 훈련\n",
    "                fake_imgs = model_generator(poisoned)\n",
    "                fake_outputs = model_discriminator(fake_imgs.detach())\n",
    "                d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "\n",
    "                # 총 Discriminator 손실\n",
    "                d_loss = d_loss_real + d_loss_fake\n",
    "                d_loss.backward()\n",
    "                optimizer_d.step()\n",
    "\n",
    "                # -----------------\n",
    "                # Generator 훈련\n",
    "                # -----------------\n",
    "                optimizer_g.zero_grad()\n",
    "\n",
    "                # Generator는 Discriminator를 속이도록 훈련\n",
    "                g_loss = criterion(model_discriminator(fake_imgs), real_labels)\n",
    "                g_loss.backward()\n",
    "                optimizer_g.step()\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}')\n",
    "        \n",
    "\n",
    "        torch.save(model_discriminator, net_d_name)\n",
    "        torch.save(model_generator, net_g_name)\n",
    "        print(\"모델을 저장하였습니다 : \", net_g_name, net_d_name)\n",
    "        \n",
    "\n",
    "        \n",
    "        print(os.getcwd())    \n",
    "        os.chdir(\"../\")\n",
    "        del model_discriminator, model_generator\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return            \n",
    "        \n",
    "    else:      \n",
    "        print(\"(모델 로드 가능)\")\n",
    "        os.chdir(\"../\")\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jO8ldOZxpSWF"
   },
   "source": [
    "### 5. 데이터의 오염 통합 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    CIFAR-10 데이터셋에 다양한 공격을 추가하는 클래스입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, perterbationset, attacked_ratio=0.2, label_attack=True, label_perterbation=True, \\\n",
    "                 overlay=True, alpha=0.5, partial_overlay=True, rotational_overlay=True, image_corruption=True, \\\n",
    "                    corruption_ratio=0.2, attack_order=\"label\", im_proc_order=\"overlay\"):\n",
    "        \"\"\" AugmentedDataset 객체를 초기화합니다. \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.perterbationset = perterbationset\n",
    "        self.attacked_ratio = attacked_ratio\n",
    "        self.label_attack = label_attack\n",
    "        self.label_perterbation = label_perterbation\n",
    "        self.overlay = overlay\n",
    "        self.alpha = alpha\n",
    "        self.partial_overlay = partial_overlay\n",
    "        self.rotational_overlay = rotational_overlay\n",
    "        self.image_corruption = image_corruption\n",
    "        self.corruption_ratio = corruption_ratio\n",
    "        self.attack_order = attack_order  # 공격 순서 설정\n",
    "        self.im_proc_order = im_proc_order\n",
    "\n",
    "        # 공격 인덱스 설정\n",
    "        self.attacked_indices = self._select_attacked_indices(self.attacked_ratio)\n",
    "\n",
    "        # Label 오염 생성 (라벨 공격이 활성화된 경우에만)\n",
    "        if self.label_attack:\n",
    "            self.attacked_labels = self._crazy_labels()\n",
    "        else:\n",
    "            self.attacked_labels = [label for _, label in self.dataset]  # 라벨 공격이 없으면 원본 라벨 사용\n",
    "\n",
    "        # Label flipping을 위한 라벨 생성 (라벨 섭동이 활성화된 경우에만)\n",
    "        if self.label_perterbation:\n",
    "            self.perbutated_labels = self._label_flipper(self.attacked_labels)\n",
    "        else:\n",
    "            self.perbutated_labels = self.attacked_labels  # 라벨 섭동이 없으면 오염된 라벨을 그대로 사용\n",
    "\n",
    "        # 변형된 이미지를 저장할 리스트 초기화\n",
    "        self.transformed_images = [None] * len(self.dataset)\n",
    "\n",
    "        # 이미지 오염 및 이미지 겹침 초기화 (이미지를 한 번만 오염 처리)\n",
    "        self.processed_images = [None] * len(self.dataset)\n",
    "        for idx in range(len(self.dataset)):\n",
    "            image, _ = self.dataset[idx]\n",
    "            image = self.__image_process__(image, idx)  # 초기화 시 한 번만 이미지 처리\n",
    "            self.processed_images[idx] = image  # 처리된 이미지 저장\n",
    "\n",
    "    def _select_attacked_indices(self, ratio):\n",
    "        \"\"\"공격 대상 샘플의 인덱스를 선택합니다.\"\"\"\n",
    "        num_attack_samples = int(ratio * len(self.dataset))\n",
    "        return random.sample(range(len(self.dataset)), num_attack_samples)\n",
    "\n",
    "    def _crazy_labels(self):\n",
    "        \"\"\"Label 오염된 라벨 리스트를 생성합니다.\"\"\"\n",
    "        attacked_labels = []\n",
    "        for idx in range(len(self.dataset)):\n",
    "            _, original_label = self.dataset[idx]\n",
    "            if idx in self.attacked_indices:\n",
    "                # 원래 라벨과 다른 무작위 라벨 생성\n",
    "                attacked_label = original_label\n",
    "                while attacked_label == original_label:\n",
    "                    attacked_label = random.randint(0, 9)\n",
    "                attacked_labels.append(attacked_label)\n",
    "            else:\n",
    "                attacked_labels.append(original_label)\n",
    "        return attacked_labels\n",
    "\n",
    "    def _label_flipper(self, target):\n",
    "        \"\"\"\n",
    "        CIFAR-10 데이터셋의 일부 샘플에 Label-Flipping 오염을 가하는 함수입니다.\n",
    "        \"\"\"\n",
    "        perbutated_labels = []\n",
    "\n",
    "        for idx in range(len(target)):\n",
    "            label = target[idx]\n",
    "\n",
    "            if idx in self.attacked_indices:\n",
    "                # 라벨 복사 후 공격 수행\n",
    "                original_label = label\n",
    "\n",
    "                if original_label == 1:\n",
    "                    label = 9\n",
    "                elif original_label == 9:\n",
    "                    label = 1\n",
    "                elif original_label == 5:\n",
    "                    label = 3\n",
    "                elif original_label == 3:\n",
    "                    label = 5\n",
    "                elif original_label == 7:\n",
    "                    label = 4\n",
    "                elif original_label == 4:\n",
    "                    label = 7\n",
    "                elif original_label == 2:\n",
    "                    label = 6\n",
    "                elif original_label == 6:\n",
    "                    label = 2\n",
    "                elif original_label == 0:\n",
    "                    label = 8\n",
    "                elif original_label == 8:\n",
    "                    label = 0\n",
    "\n",
    "            perbutated_labels.append(label)\n",
    "\n",
    "        return perbutated_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"데이터셋의 전체 길이를 반환합니다.\"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __image_process__(self, image, idx):\n",
    "        \"\"\"이미지 처리 순서 함수\"\"\"\n",
    "        if self.im_proc_order == \"overlay\":\n",
    "            image = self._overlay(image, idx) if self.overlay == True else image\n",
    "            image = self._corrupt_image(image, idx) if self.image_corruption == True else image\n",
    "        elif self.im_proc_order == \"corrupt\":\n",
    "            image = self._corrupt_image(image, idx) if self.image_corruption == True else image\n",
    "            image = self._overlay(image, idx) if self.overlay == True else image\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid im_proc_order: {self.im_proc_order}. Use 'overlay' or 'corrupt'.\")\n",
    "\n",
    "        return image\n",
    "\n",
    "    def _overlay(self, image, idx):\n",
    "        \"\"\"특정 이미지에 이미지 겹침 공격을 적용합니다.\"\"\"\n",
    "        if idx in self.attacked_indices:\n",
    "            if self.partial_overlay:\n",
    "                # 텐서를 PIL 이미지로 변환\n",
    "                pil_image = transforms.ToPILImage()(image)\n",
    "\n",
    "                # 두 개의 이미지를 랜덤으로 선택하여 중첩\n",
    "                rand_idx_1 = random.randint(0, len(self.dataset) - 1)\n",
    "                rand_idx_2 = random.randint(0, len(self.dataset) - 1)\n",
    "\n",
    "                overlay_image_1, _ = self.dataset[rand_idx_1]\n",
    "                overlay_image_2, _ = self.dataset[rand_idx_2]\n",
    "\n",
    "                # 첫 번째 이미지를 중첩\n",
    "                overlay_h_1, overlay_w_1 = overlay_image_1.shape[1], overlay_image_1.shape[2]\n",
    "                scale_factor_1 = random.uniform(0.5, 1.0)\n",
    "                new_h_1 = int(overlay_h_1 * scale_factor_1)\n",
    "                new_w_1 = int(overlay_w_1 * scale_factor_1)\n",
    "\n",
    "                overlay_image_1_pil = transforms.ToPILImage()(overlay_image_1)\n",
    "                overlay_image_1_resized = overlay_image_1_pil.resize((new_w_1, new_h_1))\n",
    "\n",
    "                x1 = random.randint(0, pil_image.size[0] - new_w_1)\n",
    "                y1 = random.randint(0, pil_image.size[1] - new_h_1)\n",
    "                pil_image.paste(overlay_image_1_resized, (x1, y1))\n",
    "\n",
    "                # 두 번째 이미지를 중첩\n",
    "                overlay_h_2, overlay_w_2 = overlay_image_2.shape[1], overlay_image_2.shape[2]\n",
    "                scale_factor_2 = random.uniform(0.5, 1.0)\n",
    "                new_h_2 = int(overlay_h_2 * scale_factor_2)\n",
    "                new_w_2 = int(overlay_w_2 * scale_factor_2)\n",
    "\n",
    "                overlay_image_2_pil = transforms.ToPILImage()(overlay_image_2)\n",
    "                overlay_image_2_resized = overlay_image_2_pil.resize((new_w_2, new_h_2))\n",
    "\n",
    "                x2 = random.randint(0, pil_image.size[0] - new_w_2)\n",
    "                y2 = random.randint(0, pil_image.size[1] - new_h_2)\n",
    "                pil_image.paste(overlay_image_2_resized, (x2, y2))\n",
    "\n",
    "                # 최종 이미지를 텐서로 변환하여 저장\n",
    "                final_image = transforms.ToTensor()(pil_image)\n",
    "                return final_image\n",
    "        \n",
    "        return image  # 이미지가 공격되지 않으면 원본 이미지 그대로 반환\n",
    "\n",
    "    def _corrupt_image(self, image, idx):\n",
    "        \"\"\"이미지의 일부 픽셀을 결손 처리합니다.\"\"\"\n",
    "        if self.image_corruption:\n",
    "            if idx in self.attacked_indices:\n",
    "                image_np = image.numpy()  # 텐서를 NumPy 배열로 변환\n",
    "                total_pixels = image_np.size\n",
    "                num_corrupted_pixels = int(total_pixels * self.corruption_ratio)\n",
    "\n",
    "                # 랜덤으로 픽셀 선택 (이미지의 플랫(flat) 배열에서 인덱스 기준)\n",
    "                indices = random.sample(range(total_pixels), num_corrupted_pixels)\n",
    "                flat_image = image_np.flatten()\n",
    "\n",
    "                # 선택된 픽셀을 0으로 설정\n",
    "                flat_image[indices] = 0\n",
    "\n",
    "                # 이미지를 원래 형태로 복원\n",
    "                image_np = flat_image.reshape(image_np.shape)\n",
    "                return torch.tensor(image_np)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        데이터셋의 특정 샘플을 반환합니다.\n",
    "        \"\"\"\n",
    "        # 원본 이미지와 라벨 가져오기\n",
    "        original_images, original_label = self.dataset[idx]\n",
    "\n",
    "        # 라벨 오염 및 이미지 오염 처리된 데이터 반환\n",
    "        image = self.processed_images[idx]\n",
    "        label = self.perbutated_labels[idx]\n",
    "\n",
    "        return original_images, original_label, image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Save 함수\n",
    "def save_dataset (data, folder_path = default_path, dat_name = \"defual_net.dat\"):\n",
    "    if os.path.exists(folder_path)== False:\n",
    "        print(\"디렉토리 없음\")\n",
    "    \n",
    "        os.mkdir(folder_path)\n",
    "        print(\"디렉토리를 만들었습니다 : \", folder_path)\n",
    "        gitignore(directory = folder_path)\n",
    "  \n",
    "    os.chdir(folder_path)\n",
    "    torch.save(data, dat_name)\n",
    "    print(\"data saved\")\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return\n",
    "\n",
    "## Data Load 함수\n",
    "def load_dataset (folder_path = default_path, dat_name = \"defual_net.dat\"):\n",
    "    if os.path.exists(folder_path)== False:\n",
    "        print(\"디렉토리 없음\")\n",
    "        return\n",
    "    \n",
    "    os.chdir(folder_path)\n",
    "    if os.path.exists(dat_name) == False:\n",
    "        print(\"데이터 없음\")\n",
    "        os.chdir(\"..//\")\n",
    "        return\n",
    "    \n",
    "    data = torch.load(dat_name)\n",
    "    os.chdir(\"..//\")\n",
    "    return data\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSiPtDKiepI3"
   },
   "source": [
    "### 실험 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3aQ0bpZHR5I"
   },
   "source": [
    "##### 1. 오염 없는 일반적 데이터 학습 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GLSYPA4eyoh"
   },
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_res = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1V7XTDue2uB",
    "outputId": "f163034d-66a5-4936-a8a2-460cdaa4d862"
   },
   "outputs": [],
   "source": [
    "acc_res = train_and_evaluate(model_res, train_loader, test_loader, net_reset=poision_sys_reset, net_name=\"default_resnet.pt\", log_name = \"default_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rMHgoh4HZAS"
   },
   "source": [
    "##### 2. 오염을 적용하는 데이터 학습 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGUuW6b4QhTX"
   },
   "outputs": [],
   "source": [
    "train_set_attacked = load_dataset(folder_path = default_path, dat_name = \"poisoned.dat\")\n",
    "if train_set_attacked == None or Data_Reset == True or poision_sys_reset == True:\n",
    "    train_set_attacked = AugmentedDataset(\n",
    "        dataset=train_set,\n",
    "        perterbationset=add_set,\n",
    "        attacked_ratio=0.4,\n",
    "        overlay=False,\n",
    "        alpha=0.25,\n",
    "        label_attack=True,\n",
    "        partial_overlay=True,\n",
    "        corruption_ratio=0.2,\n",
    "        image_corruption=True,\n",
    "        attack_order=\"label\",\n",
    "        im_proc_order=\"overlay\"\n",
    "    )\n",
    "    save_dataset(train_set_attacked, dat_name = \"poisoned.dat\")\n",
    "\n",
    "train_loader_attacked = DataLoader(dataset=train_set_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "del train_set_attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader_attacked:\n",
    "    original_images, original_labels, poisoned_images, poisoned_labels = batch\n",
    "    break  # 모든 데이터를 한 번에 가져왔으므로 반복문 종료\n",
    "\n",
    "# 확인\n",
    "print(original_images.shape)\n",
    "print(original_labels.shape)\n",
    "print(poisoned_images.shape)\n",
    "print(poisoned_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_multiple_dataloaders([train_loader, train_loader_attacked, train_loader_attacked, train_loader_attacked, train_loader_attacked], test_loader, images_per_loader=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDnonxr_x5OE"
   },
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_res_1 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcScGlNrQfXP"
   },
   "outputs": [],
   "source": [
    "acc_res_1 = train_and_evaluate(model_res_1, train_loader_attacked, test_loader, net_reset=poision_sys_reset, net_name=\"train_loader_attacked.pt\", log_name = \"train_loader_attacked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLWohjWieuJV"
   },
   "source": [
    "### 최종 비교 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "eWk22manS-sn",
    "outputId": "fbc2095f-1e0d-4395-d018-b084ad37bd81"
   },
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='ResNet_op')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "id": "AWQVUQLDyb_2",
    "outputId": "fe9cdfaa-6572-4bb1-c625-a878d5689932"
   },
   "outputs": [],
   "source": [
    "visualize_multiple_dataloaders([train_loader, train_loader_attacked, train_loader_attacked, train_loader_attacked, train_loader_attacked], test_loader, images_per_loader=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poison Activation Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_attacked_validate = load_dataset(folder_path = default_path, dat_name = \"poisoned_validate.dat\")\n",
    "if train_set_attacked_validate== None or Data_Reset == True or poision_sys_reset == True:\n",
    "    train_set_attacked_validate = AugmentedDataset(\n",
    "        dataset=train_set,\n",
    "        perterbationset=add_set,\n",
    "        attacked_ratio=1,\n",
    "        overlay=False,\n",
    "        alpha=0.25,\n",
    "        label_attack=True,\n",
    "        partial_overlay=True,\n",
    "        image_corruption= True,\n",
    "        corruption_ratio=0.2,\n",
    "        attack_order=\"label\",\n",
    "        im_proc_order=\"overlay\"\n",
    "    )\n",
    "    save_dataset(train_set_attacked_validate, dat_name = \"poisoned_validate.dat\")\n",
    "\n",
    "train_loader_attacked_validate = DataLoader(dataset=train_set_attacked_validate, batch_size=64, shuffle=True)\n",
    "\n",
    "del train_loader_attacked_validate\n",
    "del train_set_attacked_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Image Restoration Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 중독데이터 복원 AI 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CIFAR-10을 학습데이터로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_10 = Autoencoder().to(device)\n",
    "unet_10 = UNet().to(device)\n",
    "tsme_10 = TSNE_Model().to(device)\n",
    "nlm_10 = NLM_Model().to(device)\n",
    "# GAN 모델 초기화\n",
    "Gan_g_10 = Generator().cuda()\n",
    "Gan_d_10 = Discriminator().cuda()\n",
    "\n",
    "Autotest = train_model(auto_10, train_loader, device = device, net_reset= restore_sys_reset, net_name=\"auto_10.pt\", log_name = \"auto_10\")\n",
    "unettest = train_model(unet_10, train_loader, device = device, net_reset= restore_sys_reset, net_name=\"unet_10.pt\", log_name = \"unet_10\")\n",
    "#tsmetest = train_model(tsme_10, train_loader, device = device, net_reset= restore_sys_reset, net_name=\"tsme_10.pt\", log_name = \"tsme_10\")\n",
    "#nlmtest = train_model(nlm_10, train_loader, device = device, net_reset= restore_sys_reset, net_name=\"nlm_10.pt\", log_name = \"nlm_10\")\n",
    "GANtest = GAN_trainer(Gan_g_10, Gan_d_10, train_loader, device = device, net_reset= restore_sys_reset, net_name=\"unet_10.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 중독데이터를 학습데이터로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_attacked = Autoencoder().to(device)\n",
    "unet_attacked = UNet().to(device)\n",
    "\n",
    "Autotest_attaked = train_model(auto_attacked, train_loader_attacked, net_reset= restore_sys_reset, net_name=\"auto_attacked.pt\", log_name = \"auto_attacked\")\n",
    "unettest_attaked = train_model(unet_attacked, train_loader_attacked, net_reset= restore_sys_reset, net_name=\"unet_attacked.pt\", log_name = \"unet_attacked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CIFAR-100을 학습데이터로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_100 = Autoencoder().to(device)\n",
    "unet_100 = UNet().to(device)\n",
    "\n",
    "Autotest_100 = train_model(auto_100, add_loader, net_reset= restore_sys_reset, net_name=\"auto_100.pt\", log_name = \"auto_100\")\n",
    "unettest_100 = train_model(unet_100, add_loader, net_reset= restore_sys_reset, net_name=\"unet_100.pt\", log_name = \"unet_100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 학습결과 표출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 결과 확인 함수\n",
    "def show_images(restored_data, index = 0):\n",
    "    # 결과 이미지를 시각화\n",
    "    if isinstance(restored_data, restored_Items):\n",
    "        o_image, o_label, p_image, p_label, r_cond, r_image = restored_data.original_images, restored_data.original_labels, restored_data.poisoned_images, restored_data.poisoned_labels, restored_data.condition_code, restored_data.restored_images\n",
    "    else :\n",
    "        o_image, o_label, p_image, p_label, r_image = restored_data.original_images, restored_data.original_labels, restored_data.poisoned_images, restored_data.poisoned_labels, restored_data.restored_images\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    ax[0].imshow(o_image[index].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    ax[0].set_title('Original')\n",
    "    ax[1].imshow(p_image[index].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    ax[1].set_title('Poisoned')\n",
    "    ax[2].imshow(r_image[index].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    ax[2].set_title('Recovered Output')\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"Original Label:\", o_label[index])\n",
    "    print(\"Poisoned Label:\", p_label[index])\n",
    "    if isinstance(restored_data, restored_Items):\n",
    "        print(\"Poisoned condition:\", r_cond[index])\n",
    "    del restored_data\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def multi_show(restored_data, sample = 10):\n",
    "    for i in range(sample):\n",
    "        label = restored_data.poisoned_labels\n",
    "        index = random.randrange(1, len(label))\n",
    "        show_images(restored_data, index)\n",
    "    del restored_data\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 중독 데이터 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 블러감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_IO(image_in, threshold=0.5):\n",
    "    # 이미지 읽기\n",
    "    image_b = image_in.cpu().numpy().transpose((1, 2, 0))  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "    # PyTorch는 RGB 순서이므로 BGR로 변환해야 함\n",
    "    image_b = cv2.cvtColor(image_b, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # 이미지를 그레이스케일로 변환\n",
    "    gray_image = cv2.cvtColor(image_b, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Laplacian을 사용하여 이미지의 엣지 강도를 계산\n",
    "    variance = cv2.Laplacian(gray_image, cv2.CV_32F).var()\n",
    "    \n",
    "    # 분산 값이 낮으면 블러링이 발생한 것으로 판단\n",
    "    if variance < threshold:\n",
    "        return True  # 이미지가 블러됨\n",
    "    else:\n",
    "        return False  # 이미지가 선명함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 노이즈 감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_IO(image_in, threshold=5.0):\n",
    "    # 이미지 읽기\n",
    "    image_n = image_in.cpu().numpy().transpose((1, 2, 0))  # (C, H, W) -> (H, W, C)\n",
    "    # PyTorch는 RGB 순서이므로 BGR로 변환해야 함\n",
    "    image_n = cv2.cvtColor(image_n, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # 이미지를 그레이스케일로 변환\n",
    "    gray_image = cv2.cvtColor(image_n, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 이미지의 표준 편차를 계산\n",
    "    std_dev = np.std(gray_image)\n",
    "    \n",
    "    # 표준 편차가 일정 값 이상이면 노이즈가 있다고 판단\n",
    "    if std_dev > threshold:\n",
    "        return True  # 이미지에 노이즈가 있음\n",
    "    else:\n",
    "        return False  # 이미지에 노이즈 없음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 변형감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_distortion_IO(image_in, threshold=140):                ##Colour Distortion\n",
    "    # 이미지 읽기\n",
    "    image_d = image_in.cpu().numpy().transpose((1, 2, 0))  # (C, H, W) -> (H, W, C)\n",
    "    # PyTorch는 RGB 순서이므로 BGR로 변환해야 함\n",
    "    image_d = cv2.cvtColor(image_d, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # 이미지를 BGR에서 HSV로 변환\n",
    "    hsv_image = cv2.cvtColor(image_d, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # HSV 채널 분리\n",
    "    h, s, v = cv2.split(hsv_image)\n",
    "    \n",
    "    # 색상의 평균값과 표준 편차 계산\n",
    "    mean_hue = np.mean(h)\n",
    "    mean_saturation = np.mean(s)\n",
    "    mean_value = np.mean(v)\n",
    "    \n",
    "    # 왜곡이 있을 경우 평균값이 비정상적으로 클 수 있음\n",
    "    if mean_hue > threshold or mean_saturation > threshold or mean_value > threshold:\n",
    "        return True  # 색 왜곡 있음\n",
    "    else:\n",
    "        return False  # 색 왜곡 없음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 중독된 데이터 복구 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 복구데이터 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10WithModelOutputAndLabels(Dataset):\n",
    "    def __init__(self, original_images, original_labels, poisoned_images,  poisoned_labels, restored_images):\n",
    "        self.original_images= original_images\n",
    "        self.original_labels = original_labels        \n",
    "        self.poisoned_images = poisoned_images\n",
    "        self.poisoned_labels = poisoned_labels\n",
    "        self.restored_images = restored_images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.poisoned_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.original_images[idx], self.original_labels[idx], self.poisoned_images[idx], self.poisoned_labels[idx] , self.restored_images[idx]\n",
    "\n",
    "# 이미지를 모델에 통과시키고 출력 저장하는 함수\n",
    "def process_and_save_cifar10(dataloader, net_name =\"default_net.pt\" , output_filename=\"processed_cifar10_with_labels.pth\"):\n",
    "    \"\"\"\n",
    "    CIFAR-10 DataLoader에서 이미지를 처리하고, 모델의 출력과 라벨을 저장하는 함수.\n",
    "    \"\"\"\n",
    "    os.chdir(default_path)\n",
    "    if (os.path.exists(output_filename) == False and Auto_Init == True) or Data_Reset == True:\n",
    "        model = torch.load(net_name)\n",
    "        model.eval()  # 모델을 평가 모드로 설정\n",
    "        os.chdir(\"../\")\n",
    "\n",
    "        all_original_images =[]\n",
    "        all_original_labels=[]\n",
    "        all_images = []\n",
    "        all_outputs = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():  # 예측 시에는 그래디언트 계산을 하지 않음\n",
    "            for data in dataloader:\n",
    "                original_images, original_labels, images, labels = data\n",
    "                # 이미지를 GPU로 이동 (GPU가 사용 가능하면)\n",
    "                images = images.cuda() if torch.cuda.is_available() else images\n",
    "                labels = labels.cuda() if torch.cuda.is_available() else labels\n",
    "\n",
    "                # 모델을 통해 예측 결과 얻기\n",
    "                outputs = model(images)\n",
    "\n",
    "                # 결과를 리스트에 추가\n",
    "                all_original_images.append(original_images)\n",
    "                all_original_labels.append(original_labels)\n",
    "                all_images.append(images.cpu())  # CPU로 이동하여 저장\n",
    "                all_labels.append(labels.cpu())  # CPU로 이동하여 저장\n",
    "                all_outputs.append(outputs.cpu())  # CPU로 이동하여 저장\n",
    "\n",
    "        # CIFAR-10 이미지, 모델 출력, 라벨을 포함한 Dataset 생성\n",
    "        combined_dataset = CIFAR10WithModelOutputAndLabels(\n",
    "            torch.cat(all_original_images), torch.cat(all_original_labels), torch.cat(all_images), torch.cat(all_labels) , torch.cat(all_outputs)\n",
    "        )\n",
    "\n",
    "        os.chdir(default_path)\n",
    "        # PyTorch Dataset을 저장\n",
    "        torch.save(combined_dataset, output_filename)\n",
    "        print(f\"Processed data with labels saved to {output_filename}\")\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    elif Auto_Init == False:\n",
    "        print(\"학습을 생략\")\n",
    "    else :\n",
    "        print(\"학습된 파일이 있습니다\")\n",
    "    print(os.getcwd)\n",
    "    os.chdir(\"../\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class restored_Items(Dataset):\n",
    "    \" Restoration_Condition 추가\"\n",
    "    def __init__(self, original_images, original_labels, poisoned_images,  poisoned_labels, condition_code, restored_images):\n",
    "        self.original_images= original_images\n",
    "        self.original_labels = original_labels        \n",
    "        self.poisoned_images = poisoned_images\n",
    "        self.poisoned_labels = poisoned_labels\n",
    "        self.condition_code = condition_code                ## 0: non poisoned, 1: blur, 2: noise, 4:destortion = condition\n",
    "        self.restored_images = restored_images \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.poisoned_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.original_images[idx], self.original_labels[idx], self.poisoned_images[idx], self.poisoned_labels[idx], self.condition_code[idx], self.restored_images[idx]\n",
    "    \n",
    "    def _code_(self, idx):\n",
    "        if self.condition_code == 0 :\n",
    "            code_name = \" - \"\n",
    "        else : \n",
    "            code_name = \"에러\" + str(self.condition_code)\n",
    "        return code_name\n",
    "\n",
    "# 이미지를 모델에 통과시키고 출력 저장하는 함수\n",
    "def restore(dataloader, restore_reset_IO = reclass_sys_reset, net_name =\"default_net.pt\" ,net2_name = None , output_filename=\"processed_cifar10_with_labels.pth\"):\n",
    "    \"\"\"\n",
    "    CIFAR-10 DataLoader에서 이미지를 처리하고, 모델의 출력과 라벨을 저장하는 함수.\n",
    "    \"\"\"\n",
    "    os.chdir(default_path)\n",
    "    if (os.path.exists(output_filename) == False and Auto_Init == True) or Data_Reset == True or restore_reset_IO == True:\n",
    "        model = torch.load(net_name)\n",
    "        if not net2_name == None:\n",
    "             model2 = torch.load(net2_name)\n",
    "             model2.eval()\n",
    "        model.eval()  # 모델을 평가 모드로 설정\n",
    "        os.chdir(\"../\")\n",
    "\n",
    "        all_original_images =[]\n",
    "        all_original_labels=[]\n",
    "        all_images = []\n",
    "        all_outputs = []\n",
    "        all_condition_code = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():  # 예측 시에는 그래디언트 계산을 하지 않음\n",
    "            for data in dataloader:\n",
    "                original_images, original_labels, images, labels = data               \n",
    "                batch_condition_code = []\n",
    "                all_original_images.append(original_images)\n",
    "                all_original_labels.append(original_labels)\n",
    "                all_images.append(images.cpu())  # CPU로 이동하여 저장\n",
    "                all_labels.append(labels.cpu())  # CPU로 이동하여 저장\n",
    "\n",
    "                for i in range(images.size(0)): \n",
    "                    condition_code = 0\n",
    "                    if blur_IO(images[i]) == True:\n",
    "                            condition_code = condition_code + 1\n",
    "                    if noise_IO(images[i]) == True:\n",
    "                            condition_code = condition_code + 2\n",
    "                    if c_distortion_IO(images[i]) == True:\n",
    "                            condition_code = condition_code + 4\n",
    "                    batch_condition_code.append(condition_code)\n",
    "\n",
    "                # 이미지를 GPU로 이동 (GPU가 사용 가능하면)\n",
    "                images = images.cuda() if torch.cuda.is_available() else images\n",
    "                po_images = images.cuda() if torch.cuda.is_available() else images\n",
    "                temp_images = images.cuda() if torch.cuda.is_available() else images\n",
    "                #labels = labels.cuda() if torch.cuda.is_available() else labels\n",
    "                output1 = model(images)\n",
    "                outputs = po_images\n",
    "                if not net2_name == None:\n",
    "                     output2  =model2(temp_images)\n",
    "                     outputC = model2(output1)\n",
    "                \n",
    "                # 모델을 통해 예측 결과 얻기\n",
    "                for i in range(images.size(0)):\n",
    "                    if batch_condition_code[i] == 4 and not net2_name == None:\n",
    "                       outputs[i] = output2[i] \n",
    "                    elif batch_condition_code[i] >4 and not net2_name == None:\n",
    "                         outputs[i] = outputC[i]\n",
    "                    elif batch_condition_code[i] > 0:\n",
    "                         outputs[i] = output1[i]\n",
    "\n",
    "\n",
    "                # 결과를 리스트에 추가\n",
    "\n",
    "                all_condition_code.append(torch.tensor(batch_condition_code))\n",
    "                all_outputs.append(outputs.cpu())  # CPU로 이동하여 저장\n",
    "                \n",
    "\n",
    "        # CIFAR-10 이미지, 모델 출력, 라벨을 포함한 Dataset 생성\n",
    "        combined_dataset = restored_Items(\n",
    "            torch.cat(all_original_images), torch.cat(all_original_labels), torch.cat(all_images), torch.cat(all_labels), torch.cat(all_condition_code), torch.cat(all_outputs)\n",
    "        )\n",
    "\n",
    "        os.chdir(default_path)\n",
    "        # PyTorch Dataset을 저장\n",
    "        torch.save(combined_dataset, output_filename)\n",
    "        print(f\"Processed data with labels saved to {output_filename}\")\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    elif Auto_Init == False:\n",
    "        print(\"학습을 생략\")\n",
    "    else :\n",
    "        print(\"학습된 파일이 있습니다\")\n",
    "    print(os.getcwd)\n",
    "    os.chdir(\"../\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 복구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    restore(train_loader_attacked, net_name = \"auto_10.pt\", net2_name= \"unet_10.pt\", output_filename=\"combie_10.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "os.chdir(default_path)\n",
    "s_combie_10 = torch.load(\"combie_10.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "multi_show(s_combie_10, sample = 10)\n",
    "\n",
    "del s_combie_10\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    restore(train_loader_attacked, net_name = \"auto_attacked.pt\", net2_name= \"unet_attacked.pt\", output_filename=\"combie_attacked.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "os.chdir(default_path)\n",
    "s_combie_10 = torch.load(\"combie_attacked.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "multi_show(s_combie_10, sample = 10)\n",
    "\n",
    "del s_combie_10\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100\n",
    "if __name__ == \"__main__\":\n",
    "    # CIFAR-10 DataLoader 로드\n",
    "\n",
    "    # 학습된 unet_10 모델을 사용하여 CIFAR-10 데이터 처리 후 저장\n",
    "    restore(train_loader_attacked, net_name = \"auto_100.pt\", net2_name= \"unet_100.pt\", output_filename=\"combie_100.pth\")\n",
    "\n",
    "# 저장된 파일 로드 예시\n",
    "os.chdir(default_path)\n",
    "s_combie_100 = torch.load(\"combie_100.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# 데이터, 출력, 라벨 가져오기\n",
    "multi_show(s_combie_100, sample = 10)\n",
    "\n",
    "del s_combie_100\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 복원 이미지 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_combie_10 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "\n",
    "model_combie_attack = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)\n",
    "\n",
    "model_combie_100 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(default_path)\n",
    "s_combie_10 = torch.load(\"combie_10.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "train_loader_auto_10 = DataLoader(dataset=s_combie_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_10 = train_and_evaluate(model_combie_10, train_loader_auto_10, test_loader, net_reset=reclass_sys_reset, net_name=\"auto_10_7.pt\", log_name = \"auto_10_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(default_path)\n",
    "s_auto_attacked = torch.load(\"combie_attacked.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "train_loader_auto_attack = DataLoader(dataset=s_auto_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_attack = train_and_evaluate(model_combie_attack, train_loader_auto_attack, test_loader, net_reset=reclass_sys_reset, net_name=\"auto_attacked_7.pt\", log_name = \"auto_attacked_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(default_path)\n",
    "s_auto_100 = torch.load(\"combie_100.pth\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "train_loader_auto_100 = DataLoader(dataset=s_auto_100, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_100 = train_and_evaluate(model_combie_100, train_loader_auto_100, test_loader, net_reset=reclass_sys_reset, net_name=\"auto_100_7.pt\", log_name = \"auto_100_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='Poisoned')\n",
    "plt.plot(acc_auto_10, marker='x', linestyle='-', markersize=5, label='auto_10')\n",
    "\n",
    "plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='auto_attack')\n",
    "\n",
    "plt.plot(acc_auto_100, marker='x', linestyle='-', markersize=5, label='auto_100')\n",
    "\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Classification Multiplied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_auto_10_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)\n",
    "model_unet_10_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)\n",
    "\n",
    "model_auto_attacked_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)\n",
    "model_unet_attacked_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)\n",
    "\n",
    "model_auto_100_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)\n",
    "model_unet_100_2x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=20).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_auto_10_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)\n",
    "model_unet_10_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)\n",
    "\n",
    "model_auto_attacked_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)\n",
    "model_unet_attacked_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)\n",
    "\n",
    "model_auto_100_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)\n",
    "model_unet_100_3x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=30).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_auto_10_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)\n",
    "model_unet_10_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)\n",
    "\n",
    "model_auto_attacked_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)\n",
    "model_unet_attacked_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)\n",
    "\n",
    "model_auto_100_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)\n",
    "model_unet_100_5x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 신경망 생성 및 장치에 저장\n",
    "model_auto_10_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)\n",
    "model_unet_10_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)\n",
    "\n",
    "model_auto_attacked_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)\n",
    "model_unet_attacked_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)\n",
    "\n",
    "model_auto_100_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)\n",
    "model_unet_100_10x = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=100).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_10_2x = DataLoader(dataset=s_auto_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_10_2x = train_and_evaluate(model_auto_10_2x, train_loader_auto_10_2x, test_loader, net_reset=(multiplier_sys_reset or M_reset_auto_10), net_name=\"auto_10_2x.pt\", log_name = \"auto_10_2x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_10_3x = DataLoader(dataset=s_auto_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_10_3x = train_and_evaluate(model_auto_10_3x, train_loader_auto_10_3x, test_loader, net_reset=(multiplier_sys_reset or M_reset_auto_10), net_name=\"auto_10.3x\", log_name = \"auto_10_3x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_10_5x = DataLoader(dataset=s_auto_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_10_5x = train_and_evaluate(model_auto_10_5x, train_loader_auto_10_5x, test_loader, net_reset=(multiplier_sys_reset or M_reset_auto_10), net_name=\"auto_10_5x.pt\", log_name = \"auto_10_5x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_10_10x = DataLoader(dataset=s_auto_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_10_10x = train_and_evaluate(model_auto_10_10x, train_loader_auto_10_10x, test_loader, net_reset=(multiplier_sys_reset or M_reset_auto_10), net_name=\"auto_10_10x.pt\", log_name = \"auto_10_10x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='Poisoned')\n",
    "plt.plot(acc_auto_10, marker='x', linestyle='-', markersize=5, label='auto_10')\n",
    "plt.plot(acc_auto_10_2x, marker='+', linestyle='-', markersize=5, label='auto_10_2x')\n",
    "plt.plot(acc_auto_10_3x, marker='+', linestyle='-', markersize=5, label='auto_10_3x')\n",
    "plt.plot(acc_auto_10_5x, marker='+', linestyle='-', markersize=5, label='auto_10_5x')\n",
    "plt.plot(acc_auto_10_10x, marker='+', linestyle='-', markersize=5, label='auto_10_10x')\n",
    "# plt.plot(acc_unet_10, marker='x', linestyle='-', markersize=5, label='unet_10')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='auto_attack')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='unet_attack')\n",
    "# plt.plot(acc_auto_100, marker='x', linestyle='-', markersize=5, label='auto_100')\n",
    "# plt.plot(acc_unet_100, marker='x', linestyle='-', markersize=5, label='unet_100')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unet_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_10_2x = DataLoader(dataset=s_unet_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_10_2x = train_and_evaluate(model_unet_10_2x, train_loader_unet_10_2x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_10), net_name=\"unet_10_2x.pt\", log_name = \"unet_10_2x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_10_3x = DataLoader(dataset=s_unet_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_10_3x = train_and_evaluate(model_unet_10_3x, train_loader_unet_10_3x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_10), net_name=\"unet_10_3x.pt\", log_name = \"unet_10_3x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_10_5x = DataLoader(dataset=s_unet_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_10_5x = train_and_evaluate(model_unet_10_5x, train_loader_unet_10_5x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_10), net_name=\"unet_10_5x.pt\", log_name = \"unet_10_5x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_10_10x = DataLoader(dataset=s_unet_10, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_10_10x = train_and_evaluate(model_unet_10_2x, train_loader_unet_10_10x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_10), net_name=\"unet_10_10x.pt\", log_name = \"unet_10_10x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='Poisoned')\n",
    "plt.plot(acc_auto_10, marker='x', linestyle='-', markersize=5, label='auto_10')\n",
    "plt.plot(acc_auto_10_2x, marker='+', linestyle='-', markersize=5, label='auto_10_2x')\n",
    "plt.plot(acc_auto_10_3x, marker='+', linestyle='-', markersize=5, label='auto_10_3x')\n",
    "plt.plot(acc_auto_10_5x, marker='+', linestyle='-', markersize=5, label='auto_10_5x')\n",
    "plt.plot(acc_auto_10_10x, marker='+', linestyle='-', markersize=5, label='auto_10_10x')\n",
    "# plt.plot(acc_unet_10, marker='x', linestyle='-', markersize=5, label='unet_10')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='auto_attack')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='unet_attack')\n",
    "# plt.plot(acc_auto_100, marker='x', linestyle='-', markersize=5, label='auto_100')\n",
    "# plt.plot(acc_unet_100, marker='x', linestyle='-', markersize=5, label='unet_100')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### auto_attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_attacked_2x = DataLoader(dataset=s_auto_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_attacked_2x = train_and_evaluate(model_auto_attacked_2x, train_loader_auto_attacked_2x, test_loader, net_reset=(multiplier_sys_reset or M_reset_auto_attacked), net_name=\"auto_attacked_2x.pt\", log_name = \"auto_attacked_2x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_attacked_3x = DataLoader(dataset=s_auto_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_attacked_3x = train_and_evaluate(model_auto_attacked_3x, train_loader_auto_attacked_3x, test_loader, net_reset=(multiplier_sys_reset or M_reset_auto_attacked), net_name=\"auto_attacked_3x.pt\", log_name = \"auto_attacked_3x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_attacked_5x = DataLoader(dataset=s_auto_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_attacked_5x = train_and_evaluate(model_auto_attacked_5x, train_loader_auto_attacked_5x, test_loader, net_reset=(multiplier_sys_reset or M_reset_auto_attacked), net_name=\"auto_attacked_5x.pt\", log_name = \"auto_attacked_5x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_attacked_10x = DataLoader(dataset=s_auto_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_attacked_10x = train_and_evaluate(model_auto_attacked_2x, train_loader_auto_attacked_10x, test_loader, net_reset=(multiplier_sys_reset or M_reset_auto_attacked), net_name=\"auto_attacked_10x.pt\", log_name = \"auto_attacked_10x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='Poisoned')\n",
    "plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='auto_attacked')\n",
    "plt.plot(acc_auto_attacked_2x, marker='+', linestyle='-', markersize=5, label='auto_attacked_2x')\n",
    "plt.plot(acc_auto_attacked_3x, marker='+', linestyle='-', markersize=5, label='auto_attacked_3x')\n",
    "plt.plot(acc_auto_attacked_5x, marker='+', linestyle='-', markersize=5, label='auto_attacked_5x')\n",
    "plt.plot(acc_auto_attacked_10x, marker='+', linestyle='-', markersize=5, label='auto_attacked_10x')\n",
    "# plt.plot(acc_unet_10, marker='x', linestyle='-', markersize=5, label='unet_10')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='auto_attack')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='unet_attack')\n",
    "# plt.plot(acc_auto_100, marker='x', linestyle='-', markersize=5, label='auto_100')\n",
    "# plt.plot(acc_unet_100, marker='x', linestyle='-', markersize=5, label='unet_100')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unet_attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_attacked_2x = DataLoader(dataset=s_unet_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_attacked_2x = train_and_evaluate(model_unet_attacked_2x, train_loader_unet_attacked_2x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_attacked), net_name=\"unet_attacked_2x.pt\", log_name = \"unet_attacked_2x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_attacked_3x = DataLoader(dataset=s_unet_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_attacked_3x = train_and_evaluate(model_unet_attacked_3x, train_loader_unet_attacked_3x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_attacked), net_name=\"unet_attacked_3x.pt\", log_name = \"unet_attacked_3x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_attacked_5x = DataLoader(dataset=s_unet_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_attacked_5x = train_and_evaluate(model_unet_attacked_5x, train_loader_unet_attacked_5x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_attacked), net_name=\"unet_attacked_5x.pt\", log_name = \"unet_attacked_5x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_attacked_10x = DataLoader(dataset=s_unet_attacked, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_attacked_10x = train_and_evaluate(model_unet_attacked_2x, train_loader_unet_attacked_10x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_attacked), net_name=\"unet_attacked_10x.pt\", log_name = \"unet_attacked_10x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='Poisoned')\n",
    "plt.plot(acc_unet_attack, marker='x', linestyle='-', markersize=5, label='unet_attacked')\n",
    "plt.plot(acc_unet_attacked_2x, marker='+', linestyle='-', markersize=5, label='unet_attacked_2x')\n",
    "plt.plot(acc_unet_attacked_3x, marker='+', linestyle='-', markersize=5, label='unet_attacked_3x')\n",
    "plt.plot(acc_unet_attacked_5x, marker='+', linestyle='-', markersize=5, label='unet_attacked_5x')\n",
    "plt.plot(acc_unet_attacked_10x, marker='+', linestyle='-', markersize=5, label='unet_attacked_10x')\n",
    "# plt.plot(acc_unet_10, marker='x', linestyle='-', markersize=5, label='unet_10')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='auto_attack')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='unet_attack')\n",
    "# plt.plot(acc_auto_100, marker='x', linestyle='-', markersize=5, label='auto_100')\n",
    "# plt.plot(acc_unet_100, marker='x', linestyle='-', markersize=5, label='unet_100')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### auto_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_100_2x = DataLoader(dataset=s_auto_100, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_100_2x = train_and_evaluate(model_auto_100_2x, train_loader_auto_100_2x, test_loader, net_reset=(multiplier_sys_reset or M_reset_auto_100), net_name=\"auto_100_2x.pt\", log_name = \"auto_100_2x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_100_3x = DataLoader(dataset=s_auto_100, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_100_3x = train_and_evaluate(model_auto_100_3x, train_loader_auto_100_3x, test_loader, net_reset=(multiplier_sys_reset or M_reset_auto_100), net_name=\"auto_100_3x.pt\", log_name = \"auto_100_3x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_100_5x = DataLoader(dataset=s_auto_100, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_100_5x = train_and_evaluate(model_auto_100_5x, train_loader_auto_100_5x, test_loader, net_reset=(multiplier_sys_reset or M_reset_auto_100), net_name=\"auto_100_5x.pt\", log_name = \"auto_100_5x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_auto_100_10x = DataLoader(dataset=s_auto_100, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_auto_100_10x = train_and_evaluate(model_auto_100_2x, train_loader_auto_100_10x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_10), net_name=\"auto_100_10x.pt\", log_name = \"auto_100_10x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='Poisoned')\n",
    "plt.plot(acc_auto_100, marker='x', linestyle='-', markersize=5, label='auto_100')\n",
    "plt.plot(acc_auto_100_2x, marker='+', linestyle='-', markersize=5, label='auto_100_2x')\n",
    "plt.plot(acc_auto_100_3x, marker='+', linestyle='-', markersize=5, label='auto_100_3x')\n",
    "plt.plot(acc_auto_100_5x, marker='+', linestyle='-', markersize=5, label='auto_100_5x')\n",
    "plt.plot(acc_auto_100_10x, marker='+', linestyle='-', markersize=5, label='auto_100_10x')\n",
    "# plt.plot(acc_unet_10, marker='x', linestyle='-', markersize=5, label='unet_10')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='auto_attack')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='unet_attack')\n",
    "# plt.plot(acc_auto_100, marker='x', linestyle='-', markersize=5, label='auto_100')\n",
    "# plt.plot(acc_unet_100, marker='x', linestyle='-', markersize=5, label='unet_100')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unet_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_100_2x = DataLoader(dataset=s_unet_100, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_100_2x = train_and_evaluate(model_unet_100_2x, train_loader_unet_100_2x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_100), net_name=\"unet_100_2x.pt\", log_name = \"unet_100_2x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_100_3x = DataLoader(dataset=s_unet_100, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_100_3x = train_and_evaluate(model_unet_100_3x, train_loader_unet_100_3x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_100), net_name=\"unet_100_3x.pt\", log_name = \"unet_100_3x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_100_5x = DataLoader(dataset=s_unet_100, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_100_5x = train_and_evaluate(model_unet_100_5x, train_loader_unet_100_5x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_100), net_name=\"unet_100_5x.pt\", log_name = \"unet_100_5x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_100_10x = DataLoader(dataset=s_unet_100, batch_size=64, shuffle=True)\n",
    "\n",
    "acc_unet_100_10x = train_and_evaluate(model_unet_100_2x, train_loader_unet_100_10x, test_loader, net_reset=(multiplier_sys_reset or M_reset_unet_100), net_name=\"unet_100_10x.pt\", log_name = \"unet_100_10x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(acc_res, marker='o', linestyle='-', markersize=5, label='ResNet_Default')\n",
    "plt.plot(acc_res_1, marker='o', linestyle='-', markersize=5, label='Poisoned')\n",
    "plt.plot(acc_unet_100, marker='x', linestyle='-', markersize=5, label='unet_100')\n",
    "plt.plot(acc_unet_100_2x, marker='+', linestyle='-', markersize=5, label='unet_100_2x')\n",
    "plt.plot(acc_unet_100_3x, marker='+', linestyle='-', markersize=5, label='unet_100_3x')\n",
    "plt.plot(acc_unet_100_5x, marker='+', linestyle='-', markersize=5, label='unet_100_5x')\n",
    "plt.plot(acc_unet_100_10x, marker='+', linestyle='-', markersize=5, label='unet_100_10x')\n",
    "# plt.plot(acc_unet_10, marker='x', linestyle='-', markersize=5, label='unet_10')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='auto_attack')\n",
    "# plt.plot(acc_auto_attack, marker='x', linestyle='-', markersize=5, label='unet_attack')\n",
    "# plt.plot(acc_auto_100, marker='x', linestyle='-', markersize=5, label='auto_100')\n",
    "# plt.plot(acc_unet_100, marker='x', linestyle='-', markersize=5, label='unet_100')\n",
    "\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "kSD6sI1ojEfo",
    "Nc6NvqDWjJjl",
    "UVF7GSn9jOB5",
    "M5haTn0vlaFa",
    "tLWohjWieuJV"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
